{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"pytorch_bert_final.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a7a75abdfddd4e27816a11efaf8ffb56":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_469ff5c23063421d8930720a2fa36686","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5d36541a413348999e810c7d7cfc3828","IPY_MODEL_5cd033f12a8d407fa215c6c27e43026f"]}},"469ff5c23063421d8930720a2fa36686":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5d36541a413348999e810c7d7cfc3828":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5e6bccac170e465f923263fd72a329d8","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":580,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":580,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f095e14d236f4e58a6d10e54487d2d86"}},"5cd033f12a8d407fa215c6c27e43026f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_58bcb7c26c704ca5a9aa6422bd5455c2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 580/580 [00:05&lt;00:00, 104B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_41ae77f398454bf99febf03b04c5b4cd"}},"5e6bccac170e465f923263fd72a329d8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f095e14d236f4e58a6d10e54487d2d86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"58bcb7c26c704ca5a9aa6422bd5455c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"41ae77f398454bf99febf03b04c5b4cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"30c63aa3e4714af381738ef14293ac29":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_37ea910fa2004268a506f719704a17a0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6fad6622c68a4c20b774ed52b9863581","IPY_MODEL_41438c943058403ba6a33904682161ed"]}},"37ea910fa2004268a506f719704a17a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6fad6622c68a4c20b774ed52b9863581":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6f1ef5a44818497faac2f5125cbe5999","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":780030,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":780030,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2d9678853e434604b28b39ab9473b41f"}},"41438c943058403ba6a33904682161ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_857476e3897c4303b4946e22c6e414b2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 780k/780k [00:03&lt;00:00, 195kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e1dd97e610184d159a4f9ba8d2ebf96e"}},"6f1ef5a44818497faac2f5125cbe5999":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2d9678853e434604b28b39ab9473b41f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"857476e3897c4303b4946e22c6e414b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e1dd97e610184d159a4f9ba8d2ebf96e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2d83bd417087497e9acd916695cad1b1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_acb01d00cb1c4bc2aaee22dd384b3d56","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5e3a37ec58e64c86879e90b571465836","IPY_MODEL_70519768300d4798ace157e6533eb837"]}},"acb01d00cb1c4bc2aaee22dd384b3d56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5e3a37ec58e64c86879e90b571465836":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_cea5201c1b3f4a479dcfdb18e3f1e7da","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":543450723,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":543450723,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0140a7d637244a5fbea5b170e9d9dab8"}},"70519768300d4798ace157e6533eb837":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_031340d350ef4ad9b122a9595522b939","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 543M/543M [00:43&lt;00:00, 12.5MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_166d4546d62843d384a86bc48cdb6de6"}},"cea5201c1b3f4a479dcfdb18e3f1e7da":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0140a7d637244a5fbea5b170e9d9dab8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"031340d350ef4ad9b122a9595522b939":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"166d4546d62843d384a86bc48cdb6de6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f54adb21d99f498289ecfb15cb891f0c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e0c18042906e4a9e9625815a3ef881b0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_92a3bd5df12e44e296a07387042e6273","IPY_MODEL_f47bdc7b3fc24ae4a1a09114d3aedff8"]}},"e0c18042906e4a9e9625815a3ef881b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"92a3bd5df12e44e296a07387042e6273":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_dbd995f56da04dab99dd1f9f0b12ec8f","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":580,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":580,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dc42078271fc48338fa03cccacf27767"}},"f47bdc7b3fc24ae4a1a09114d3aedff8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_799d9f8f185e4eeb977e818445b85e4e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 580/580 [00:02&lt;00:00, 217B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3200ec9c61e74ee79e09fa04f0d68adf"}},"dbd995f56da04dab99dd1f9f0b12ec8f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"dc42078271fc48338fa03cccacf27767":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"799d9f8f185e4eeb977e818445b85e4e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3200ec9c61e74ee79e09fa04f0d68adf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5127b3644ffa40308e9ad903896273fc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8d166018908a471294df35b4b1e1f123","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_40a160cc1b124ffe81b38505344b3f57","IPY_MODEL_953752c94c7a46a08c1bf3721870a75b"]}},"8d166018908a471294df35b4b1e1f123":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"40a160cc1b124ffe81b38505344b3f57":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9c5895a8bdc14b4f9ab6de7ebdd734be","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":717153,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":717153,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_929dda9d73354fd1b5c668cc5e6f0c99"}},"953752c94c7a46a08c1bf3721870a75b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a51dc62df47c417aa28475b505bc6c90","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 717k/717k [00:01&lt;00:00, 407kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a94fd9dd1e2d49d899f92c27c9c3c4a5"}},"9c5895a8bdc14b4f9ab6de7ebdd734be":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"929dda9d73354fd1b5c668cc5e6f0c99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a51dc62df47c417aa28475b505bc6c90":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a94fd9dd1e2d49d899f92c27c9c3c4a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"68c1df0a1a084eddb9674f7a55fc218a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_45d96a8e3bf34885bb37dcaf0821e0dc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e56eb652b0834f09b8a2c596f3d9d715","IPY_MODEL_7932ecafeba146bc95b153c9899cceeb"]}},"45d96a8e3bf34885bb37dcaf0821e0dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e56eb652b0834f09b8a2c596f3d9d715":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1dbc4525871c460c983b83ce7d1214e3","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":543450661,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":543450661,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_301ce39aff0347588f61ce99b7a3483f"}},"7932ecafeba146bc95b153c9899cceeb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4b4de35a3e1743ba8ae66f89413719ba","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 543M/543M [00:10&lt;00:00, 51.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bf3b792c1a074b589249a40442080eaf"}},"1dbc4525871c460c983b83ce7d1214e3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"301ce39aff0347588f61ce99b7a3483f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4b4de35a3e1743ba8ae66f89413719ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bf3b792c1a074b589249a40442080eaf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"wc1hTi9VdMDy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":615},"executionInfo":{"status":"ok","timestamp":1593473237439,"user_tz":420,"elapsed":9285,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}},"outputId":"7c2c80c1-25b2-4d2c-b128-704b54056371"},"source":["!pip3 install transformers"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n","\u001b[K     |████████████████████████████████| 757kB 2.7MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 13.5MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers==0.8.0-rc4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/bd/e5abec46af977c8a1375c1dca7cb1e5b3ec392ef279067af7f6bc50491a0/tokenizers-0.8.0rc4-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 18.9MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 38.4MB/s \n","\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=6e80be1e7a4f159a29be7d4a04f3a0ca249ff9bea9d4362a04a1cebecc77f11c\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.0rc4 transformers-3.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2KoFOr_5jze3","colab":{},"executionInfo":{"status":"ok","timestamp":1593473242644,"user_tz":420,"elapsed":11473,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}}},"source":["import pandas as pd\n","import json\n","from sklearn.model_selection import train_test_split\n","import torch\n","import random\n","import numpy as np\n","import tensorflow as tf\n","import transformers\n","import torch\n","from torch.utils.data import TensorDataset, random_split\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","import time\n","import datetime\n","import numpy as np\n","from transformers import get_linear_schedule_with_warmup\n","from scipy.special import softmax"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jKSzwvOiPVuI","colab_type":"text"},"source":["## Set Model Type and Hyperparameters"]},{"cell_type":"code","metadata":{"id":"4UfyMT8WmlLh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593473242645,"user_tz":420,"elapsed":10244,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}}},"source":["# orig parameters\n","# learning_rate_param = 2e-5\n","# epsilon_for_adam = 1e-8\n","# num_epochs = 2\n","# batch_size = 32\n","# warmup_steps = 0"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"xjiQ6iZ_Yrgt","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593473242646,"user_tz":420,"elapsed":9578,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}}},"source":["# OPTIMAL PARAMETERS\n","#run_name = \"T1-AR-Accenture-contrast2_aubBERT\"\n","#pretrained_model_name = 'aubmindlab/bert-base-arabert'\n","#learning_rate_param = 1.5e-05\n","#epsilon_for_adam = 1.5e-8\n","#num_epochs = 2\n","#batch_size = 32\n","#warmup_steps = 0\n","#output_name = \"aubmind\" + \"_\" +str(learning_rate_param) +\"_\" + str(epsilon_for_adam) + \"_\" +str(num_epochs) + str(batch_size)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"1_ndZsR0PU04","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593473242646,"user_tz":420,"elapsed":9087,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}}},"source":["pretrained_model_name = 'aubmindlab/bert-base-arabertv01'\n","learning_rate_param = 2e-05\n","epsilon_for_adam = 1.5e-8\n","num_epochs = 2\n","batch_size = 32\n","warmup_steps = 0\n","output_name = \"aubmind\" + \"_\" +str(learning_rate_param) +\"_\" + str(epsilon_for_adam) + \"_\" +str(num_epochs) + str(batch_size)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cg52dqbgRDww","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":164,"referenced_widgets":["a7a75abdfddd4e27816a11efaf8ffb56","469ff5c23063421d8930720a2fa36686","5d36541a413348999e810c7d7cfc3828","5cd033f12a8d407fa215c6c27e43026f","5e6bccac170e465f923263fd72a329d8","f095e14d236f4e58a6d10e54487d2d86","58bcb7c26c704ca5a9aa6422bd5455c2","41ae77f398454bf99febf03b04c5b4cd","30c63aa3e4714af381738ef14293ac29","37ea910fa2004268a506f719704a17a0","6fad6622c68a4c20b774ed52b9863581","41438c943058403ba6a33904682161ed","6f1ef5a44818497faac2f5125cbe5999","2d9678853e434604b28b39ab9473b41f","857476e3897c4303b4946e22c6e414b2","e1dd97e610184d159a4f9ba8d2ebf96e","2d83bd417087497e9acd916695cad1b1","acb01d00cb1c4bc2aaee22dd384b3d56","5e3a37ec58e64c86879e90b571465836","70519768300d4798ace157e6533eb837","cea5201c1b3f4a479dcfdb18e3f1e7da","0140a7d637244a5fbea5b170e9d9dab8","031340d350ef4ad9b122a9595522b939","166d4546d62843d384a86bc48cdb6de6"]},"executionInfo":{"status":"ok","timestamp":1593473299122,"user_tz":420,"elapsed":64881,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}},"outputId":"918c4fdf-1668-468c-b9bd-c549aaf04499"},"source":["def download_pretrained_model(pretrained_model_name):\n","  if pretrained_model_name == 'asafaya/bert-base-arabic':\n","    tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'asafaya/bert-base-arabic')\n","    model = torch.hub.load('huggingface/pytorch-transformers', 'model', 'asafaya/bert-base-arabic')\n","  elif pretrained_model_name == \"aubmindlab/bert-base-arabertv01\":\n","    tokenizer = transformers.AutoTokenizer.from_pretrained(\"aubmindlab/bert-base-arabertv01\" ,do_lower_case=False)\n","    model = transformers.AutoModel.from_pretrained(\"aubmindlab/bert-base-arabertv01\")\n","  else:\n","    print('cannot find model.')\n","  return tokenizer, model\n","tokenizer, model = download_pretrained_model(pretrained_model_name)"],"execution_count":6,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a7a75abdfddd4e27816a11efaf8ffb56","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=580.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"30c63aa3e4714af381738ef14293ac29","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=780030.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d83bd417087497e9acd916695cad1b1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=543450723.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Lp56zQj5jze8"},"source":["## Find GPU"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"roRpUuj7lgUX","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1593473309134,"user_tz":420,"elapsed":572,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}},"outputId":"6878143f-7913-4b59-ff05-5d64a893a8db"},"source":["# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":7,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla K80\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UnlWC7ujjze8","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593473325426,"user_tz":420,"elapsed":16406,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}},"outputId":"d0cb1e31-a22c-4ba3-bd6c-2444221018b8"},"source":["# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"onPZ9ljvjzfA","colab":{},"executionInfo":{"status":"ok","timestamp":1593473349562,"user_tz":420,"elapsed":527,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}}},"source":["# read in labels\n","labels = pd.read_table(\"CT20-AR-Train-T1-Labels.txt\", header = None)\n","labels.columns = ['Topic', 'id', 'label']\n","## read in the json and convert to a pandas dataframe\n","data = []\n","with open(\"CT20-AR-Train-T1-Tweets.json\") as f:\n","    for line in f:\n","        data.append(json.loads(line))\n","tweets = pd.DataFrame.from_records(data)\n","tweets = tweets[['id', 'full_text']]\n","df = tweets.merge(labels)\n","Xd = df['full_text'].values\n","yd = df['label'].values"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"_2n7wa-dYbPA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593473353993,"user_tz":420,"elapsed":526,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}},"outputId":"553cd964-2031-4e98-f627-f857ba6f96f4"},"source":["yd.sum()"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["458"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"7Q5U2I7PYVA2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593473356141,"user_tz":420,"elapsed":528,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}},"outputId":"5c2b618d-f51f-417a-f1de-a8d31a20b2bf"},"source":["len(tweets)"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1500"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"NePDMY3LIc76","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593473359099,"user_tz":420,"elapsed":499,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}},"outputId":"fa9a34fc-87a5-443b-8787-e03b5c3aacb2"},"source":["yd.sum()/len(yd)"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.30533333333333335"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MNDHZl8sjzfD"},"source":["## Make a test set that we won't train with.\n","\n","Dev set will be made later from the training set"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-7oyCGKGjzfD","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593473365459,"user_tz":420,"elapsed":656,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}},"outputId":"b6db4c31-92ac-4906-8b38-8fa9701223e9"},"source":["X, X_test, y, y_test = train_test_split(Xd, yd, test_size=0.2, random_state=1)\n","#X_train, dev_x_test, dev_y_train, dev_y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n","print(f'training set: {len(X)}, test set: {len(y_test)}')"],"execution_count":16,"outputs":[{"output_type":"stream","text":["training set: 1200, test set: 300\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Px3awkfSPHSQ","colab_type":"text"},"source":["## Add in AWS double translation\n","\n","There's a big class imbalance, so i translated the 365 positive classes to English in back using AWS in hopes that upsampling will improve accuracy"]},{"cell_type":"code","metadata":{"id":"mTVw_Av6PPe2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593473367711,"user_tz":420,"elapsed":564,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}}},"source":["en_ar = pd.read_csv('english_to_arabic.csv')\n","y_upsample = np.ones(len(en_ar), dtype = int)\n","X = np.concatenate([X, en_ar.en_to_ar_trans])\n","y = np.concatenate([y, y_upsample])\n","\n","#ar_en = pd.read_csv('arabic_to_english.csv')\n","#y_upsample2 = np.ones(len(ar_en), dtype = int)\n","#X = np.concatenate([X, ar_en.ar_trans])\n","#y = np.concatenate([y, y_upsample2])"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"6XDMIwa6aga2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593473464326,"user_tz":420,"elapsed":522,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}}},"source":["train = pd.DataFrame({'X_train':X, 'y_train':y})\n","test = pd.DataFrame({\"X_test\":X_test, 'y_test': y_test})"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AzCg7XJbK17H","colab_type":"text"},"source":["\n","\n","## Try out aubmindlab's v01 model"]},{"cell_type":"code","metadata":{"id":"sa5pS0hWK984","colab_type":"code","colab":{}},"source":["#tokenizer = transformers.AutoTokenizer.from_pretrained(\"aubmindlab/bert-base-arabertv01\" ,do_lower_case=False)\n","#model = transformers.AutoModel.from_pretrained(\"aubmindlab/bert-base-arabertv01\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HGLdODNro7tD","colab_type":"text"},"source":["## other aubmindlab model... just for contrastive run"]},{"cell_type":"code","metadata":{"id":"gKKZNgDnoki5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":164,"referenced_widgets":["f54adb21d99f498289ecfb15cb891f0c","e0c18042906e4a9e9625815a3ef881b0","92a3bd5df12e44e296a07387042e6273","f47bdc7b3fc24ae4a1a09114d3aedff8","dbd995f56da04dab99dd1f9f0b12ec8f","dc42078271fc48338fa03cccacf27767","799d9f8f185e4eeb977e818445b85e4e","3200ec9c61e74ee79e09fa04f0d68adf","5127b3644ffa40308e9ad903896273fc","8d166018908a471294df35b4b1e1f123","40a160cc1b124ffe81b38505344b3f57","953752c94c7a46a08c1bf3721870a75b","9c5895a8bdc14b4f9ab6de7ebdd734be","929dda9d73354fd1b5c668cc5e6f0c99","a51dc62df47c417aa28475b505bc6c90","a94fd9dd1e2d49d899f92c27c9c3c4a5","68c1df0a1a084eddb9674f7a55fc218a","45d96a8e3bf34885bb37dcaf0821e0dc","e56eb652b0834f09b8a2c596f3d9d715","7932ecafeba146bc95b153c9899cceeb","1dbc4525871c460c983b83ce7d1214e3","301ce39aff0347588f61ce99b7a3483f","4b4de35a3e1743ba8ae66f89413719ba","bf3b792c1a074b589249a40442080eaf"]},"executionInfo":{"status":"ok","timestamp":1591222655854,"user_tz":420,"elapsed":18169,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}},"outputId":"d78d1190-2e3c-4ede-df75-d3d91a9c7963"},"source":["tokenizer = transformers.AutoTokenizer.from_pretrained(\"aubmindlab/bert-base-arabert\",\n","                                                       do_lower_case=False,\n","                                                       do_basic_tokenize=True)\n","model = transformers.AutoModel.from_pretrained(\"aubmindlab/bert-base-arabert\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f54adb21d99f498289ecfb15cb891f0c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=580.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5127b3644ffa40308e9ad903896273fc","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=717153.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"68c1df0a1a084eddb9674f7a55fc218a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=543450661.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0EFeDQVhIJXv","colab_type":"text"},"source":["## Original - asafaya bert"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ez_t-a3NjzfH","colab":{}},"source":["#tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'asafaya/bert-base-arabic')\n","#model = torch.hub.load('huggingface/pytorch-transformers', 'model', 'asafaya/bert-base-arabic')    # Download model and configuration from S3 and cache."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jZsYZM9KjzfK"},"source":["## Tokenizing\n","\n","Bert requires special beginning and ending tokens that can be added as a default by huggingface tokenizers. We'll look at a quick example below. These padding tokens are encoded as 2 and 3. We also need to pad all strings to the same length. Finally we need an attention mask to separate padded strings from real strings. These are all creatable in tokenizer.encode_plus()"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"OTy_5CUQjzfK"},"source":["Find the longest tweet:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Q64aAQCyjzfL","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1591222659626,"user_tz":420,"elapsed":530,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}},"outputId":"d1c282ee-3beb-48ee-fdba-446b28e24c62"},"source":["max_len = [len(x.split()) for x in X.tolist()]\n","print(f'longest tweet is: {max(max_len)} words')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["longest tweet is: 63 words\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"01mhVeaQjzfO"},"source":["## Tokenize"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sBDmS39mjzfO","colab":{"base_uri":"https://localhost:8080/","height":207},"executionInfo":{"status":"ok","timestamp":1591222661679,"user_tz":420,"elapsed":1581,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}},"outputId":"4b5177e0-e3ca-4286-e70f-4e9d7d09f6ed"},"source":["input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in X:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 63,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(y)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', X[10])\n","print('Token IDs:', input_ids[10])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Original:  🔥عـاجل | \n","🔴 \n","بلومبرغ: تركيا تطلب من الولايات المتحدة نشر بطاريتي باتريوت لردع روسيا في إدلب\n","Token IDs: tensor([29756, 29759, 29759, 29759, 55374,    23, 33519, 14562,   857,   445,\n","        46268,  7797,   445, 45690,   980,  6676, 32566,   981,  1007, 55232,\n","          113,  7946,   996, 35706,   781, 11765, 29758, 29757, 29757, 29757,\n","        29757, 29757, 29757, 29757, 29757, 29757, 29757, 29757, 29757, 29757,\n","        29757, 29757, 29757, 29757, 29757, 29757, 29757, 29757, 29757, 29757,\n","        29757, 29757, 29757, 29757, 29757, 29757, 29757, 29757, 29757, 29757,\n","        29757, 29757, 29757])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"m_2jTdfUjzfR"},"source":["## Train Dev Split"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aKsHuWV4jzfS","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1591222663103,"user_tz":420,"elapsed":439,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}},"outputId":"b4da4bcc-242d-474a-f4fc-2f7f9e6720f5"},"source":["# Combine the training inputs into a TensorDataset.\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","# Create a 90-10 train-validation split.\n","\n","# Calculate the number of samples to include in each set.\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","# lets try a split where we don't randomize. This keeps translations ONLY\n","# in the training set\n","#train_dataset = torch.utils.data.Subset(dataset, list(range((val_size+1),len(dataset))))\n","#val_dataset = torch.utils.data.Subset(dataset, list(range(val_size)))\n","\n","# original split -Divide the dataset by randomly selecting samples.\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1,408 training samples\n","  157 validation samples\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"8K1Yuck5jzfU"},"source":["## Create an Iterator"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"W8hFH5AKjzfV"},"source":["With iterators we don't need to load the full dataset into memory"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UsURAfL8jzfV","colab":{}},"source":["# The DataLoader needs to know our batch size for training, so we specify it \n","# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n","# size of 16 or 32.\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order. \n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ovXGg5iyjzfY","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1591222671631,"user_tz":420,"elapsed":6169,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}},"outputId":"c6a3a7ea-8db2-4b9d-d19e-effe9b0e5f16"},"source":["# Load BertForSequenceClassification, the pretrained BERT model with a single \n","# linear classification layer on top. \n","model = BertForSequenceClassification.from_pretrained(\n","    pretrained_model_name, # Arabic BERT\n","    num_labels = 2, # The number of output labels--2 for binary classification.\n","                    # You can increase this for multi-class tasks.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(64000, 768, padding_idx=29757)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":74}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"peqUlu1-jzfb","colab":{"base_uri":"https://localhost:8080/","height":612},"executionInfo":{"status":"ok","timestamp":1591222673041,"user_tz":420,"elapsed":957,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}},"outputId":"eed2a59f-c39d-4d14-b4bc-d9b0409ac3d2"},"source":["params = list(model.named_parameters())\n","\n","print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The BERT model has 201 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","bert.embeddings.word_embeddings.weight                  (64000, 768)\n","bert.embeddings.position_embeddings.weight                (512, 768)\n","bert.embeddings.token_type_embeddings.weight                (2, 768)\n","bert.embeddings.LayerNorm.weight                              (768,)\n","bert.embeddings.LayerNorm.bias                                (768,)\n","\n","==== First Transformer ====\n","\n","bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.query.bias                (768,)\n","bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n","bert.encoder.layer.0.attention.self.key.bias                  (768,)\n","bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.value.bias                (768,)\n","bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n","bert.encoder.layer.0.attention.output.dense.bias              (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n","bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n","bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n","bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n","bert.encoder.layer.0.output.dense.bias                        (768,)\n","bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n","bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n","\n","==== Output Layer ====\n","\n","bert.pooler.dense.weight                                  (768, 768)\n","bert.pooler.dense.bias                                        (768,)\n","classifier.weight                                           (2, 768)\n","classifier.bias                                                 (2,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ZHmcypb0jzfe"},"source":["## Helper Functions"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LEj2guYyjzfe","colab":{}},"source":["# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"c8s3vmBLjzfh"},"source":["## Set default parameters"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NCbupAjejzfh","colab":{}},"source":["# AdamW is adam with weight decay\n","optimizer = AdamW(model.parameters(),\n","                  lr = learning_rate_param, # args.learning_rate\n","                  eps = epsilon_for_adam # args.adam_epsilon\n","                )\n","\n","# Number of training epochs. The BERT authors recommend between 2 and 4. \n","# Lets try 2.\n","epochs = num_epochs\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = warmup_steps, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"psQcXKRIjzfj"},"source":["## Time to fine-tune BERT!"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jLy9zV1ujzfj","colab":{"base_uri":"https://localhost:8080/","height":476},"executionInfo":{"status":"ok","timestamp":1591222713184,"user_tz":420,"elapsed":33137,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}},"outputId":"76e0e4d9-15ba-41e0-d637-2b289a6a185e"},"source":["seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# We'll store a number of quantities such as training and validation loss, \n","# validation accuracy, and timings.\n","training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # The documentation for this `model` function is here: \n","        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","        # It returns different numbers of parameters depending on what arguments\n","        # arge given and what flags are set. For our useage here, it returns\n","        # the loss (because we provided labels) and the \"logits\"--the model\n","        # outputs prior to activation.\n","        loss, logits = model(b_input_ids, \n","                             token_type_ids=None, \n","                             attention_mask=b_input_mask, \n","                             labels=b_labels)\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using \n","        # the `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            # The documentation for this `model` function is here: \n","            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","            # Get the \"logits\" output by the model. The \"logits\" are the output\n","            # values prior to applying an activation function like the softmax.\n","            (loss, logits) = model(b_input_ids, \n","                                   token_type_ids=None, \n","                                   attention_mask=b_input_mask,\n","                                   labels=b_labels)\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 2 ========\n","Training...\n","  Batch    40  of     44.    Elapsed: 0:00:14.\n","\n","  Average training loss: 0.54\n","  Training epcoh took: 0:00:16\n","\n","Running Validation...\n","  Accuracy: 0.79\n","  Validation Loss: 0.47\n","  Validation took: 0:00:01\n","\n","======== Epoch 2 / 2 ========\n","Training...\n","  Batch    40  of     44.    Elapsed: 0:00:14.\n","\n","  Average training loss: 0.43\n","  Training epcoh took: 0:00:16\n","\n","Running Validation...\n","  Accuracy: 0.82\n","  Validation Loss: 0.42\n","  Validation took: 0:00:01\n","\n","Training complete!\n","Total training took 0:00:32 (h:mm:ss)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YW1VtmDkjzfm","colab":{"base_uri":"https://localhost:8080/","height":159},"executionInfo":{"status":"ok","timestamp":1591222717278,"user_tz":420,"elapsed":697,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}},"outputId":"8e3201a2-43db-4355-cdca-c8f0aae2c1bf"},"source":["# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. Accur.</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.54</td>\n","      <td>0.47</td>\n","      <td>0.79</td>\n","      <td>0:00:16</td>\n","      <td>0:00:01</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.43</td>\n","      <td>0.42</td>\n","      <td>0.82</td>\n","      <td>0:00:16</td>\n","      <td>0:00:01</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n","epoch                                                                         \n","1               0.54         0.47           0.79       0:00:16         0:00:01\n","2               0.43         0.42           0.82       0:00:16         0:00:01"]},"metadata":{"tags":[]},"execution_count":79}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wiyRGd2-u1AM","colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"status":"ok","timestamp":1591222718396,"user_tz":420,"elapsed":655,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}},"outputId":"c08e8e1f-0d45-4fd7-a942-4ba0e5bd1d34"},"source":["import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","import seaborn as sns\n","\n","# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAvUAAAGaCAYAAACPCLyfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd1RU59YG8GcGZuhNigWsKKA0EWvEghUVK4jtIpZYYr0muVGjppiY3KixYTSxJWrsNBtiwZJ4QzRqIhbUiLEgqCNIGykDM98ffkwyDgiDwAF8fmu5knnPOe/ZM3KWe1722UekUqlUICIiIiKiGkssdABERERERPR6mNQTEREREdVwTOqJiIiIiGo4JvVERERERDUck3oiIiIiohqOST0RERERUQ3HpJ6I3nhJSUlwdnZGaGhoueeYN28enJ2dKzCq2qukz9vZ2Rnz5s0r0xyhoaFwdnZGUlJShccXEREBZ2dnnDt3rsLnJiKqLPpCB0BE9DJdkuPY2Fg4ODhUYjQ1z/Pnz/Htt98iOjoaT548QZ06deDt7Y1p06bB0dGxTHPMmjULR48eRVRUFFq2bFnsPiqVCj179kRmZibOnj0LQ0PDinwblercuXM4f/48QkJCYG5uLnQ4WpKSktCzZ0+MGTMGH330kdDhEFENwKSeiKqdpUuXary+ePEi9uzZgxEjRsDb21tjW506dV77fPb29oiPj4eenl655/jss8/w6aefvnYsFWHhwoU4fPgw/P390b59e8hkMpw8eRKXL18uc1IfGBiIo0ePIjw8HAsXLix2n19//RUPHz7EiBEjKiShj4+Ph1hcNb9APn/+PNauXYuhQ4dqJfWDBw/GgAEDIJFIqiQWIqKKwKSeiKqdwYMHa7wuLCzEnj170Lp1a61tL8vOzoapqalO5xOJRDAwMNA5zn+qLglgTk4OYmJi4OPjg6+//lo9PmPGDOTn55d5Hh8fH9SvXx8HDx7EBx98AKlUqrVPREQEgBdfACrC6/4dVBQ9Pb3X+oJHRCQE1tQTUY3Vo0cPBAcH4/r165g4cSK8vb0xaNAgAC+S+5UrV2L48OHo0KED3Nzc0Lt3byxfvhw5OTka8xRX4/3PsVOnTiEgIADu7u7w8fHBV199hYKCAo05iqupLxrLysrCxx9/jE6dOsHd3R0jR47E5cuXtd7Ps2fPMH/+fHTo0AFeXl4YO3Ysrl+/juDgYPTo0aNMn4lIJIJIJCr2S0ZxiXlJxGIxhg4divT0dJw8eVJre3Z2No4dOwYnJyd4eHjo9HmXpLiaeqVSie+++w49evSAu7s7/P39ceDAgWKPT0xMxCeffIIBAwbAy8sLnp6eGDZsGPbt26ex37x587B27VoAQM+ePeHs7Kzx919STX1aWho+/fRTdOvWDW5ubujWrRs+/fRTPHv2TGO/ouPj4uKwefNm9OrVC25ubujbty8iIyPL9Fno4saNG5g+fTo6dOgAd3d39O/fHxs3bkRhYaHGfikpKZg/fz58fX3h5uaGTp06YeTIkRoxKZVK/PDDDxg4cCC8vLzQpk0b9O3bFx9++CEUCkWFx05EFYcr9URUoyUnJyMkJAR+fn7o06cPnj9/DgB4/PgxwsLC0KdPH/j7+0NfXx/nz5/Hpk2bkJCQgM2bN5dp/jNnzmDnzp0YOXIkAgICEBsbiy1btsDCwgJTp04t0xwTJ05EnTp1MH36dKSnp+P777/H5MmTERsbq/6tQn5+PsaPH4+EhAQMGzYM7u7uuHnzJsaPHw8LC4syfx6GhoYYMmQIwsPDcejQIfj7+5f52JcNGzYM69evR0REBPz8/DS2HT58GLm5uQgICABQcZ/3y7788kts27YN7dq1w7hx45CamorFixejYcOGWvueP38eFy5cQPfu3eHg4KD+rcXChQuRlpaGKVOmAABGjBiB7OxsHD9+HPPnz4eVlRWAV9/LkZWVhVGjRuHevXsICAhAq1atkJCQgF27duHXX3/Fvn37tH5DtHLlSuTm5mLEiBGQSqXYtWsX5s2bh0aNGmmVkZXXlStXEBwcDH19fYwZMwY2NjY4deoUli9fjhs3bqh/W1NQUIDx48fj8ePHGD16NJo0aYLs7GzcvHkTFy5cwNChQwEA69evx5o1a+Dr64uRI0dCT08PSUlJOHnyJPLz86vNb6SIqBgqIqJqLjw8XOXk5KQKDw/XGPf19VU5OTmp9u7dq3VMXl6eKj8/X2t85cqVKicnJ9Xly5fVYw8ePFA5OTmp1qxZozXm6empevDggXpcqVSqBgwYoOrcubPGvHPnzlU5OTkVO/bxxx9rjEdHR6ucnJxUu3btUo/9+OOPKicnJ9W6des09i0a9/X11XovxcnKylJNmjRJ5ebmpmrVqpXq8OHDZTquJGPHjlW1bNlS9fjxY43xoKAglaurqyo1NVWlUr3+561SqVROTk6quXPnql8nJiaqnJ2dVWPHjlUVFBSox69evapydnZWOTk5afzdyOVyrfMXFhaq/vWvf6natGmjEd+aNWu0ji9S9PP266+/qsdWrFihcnJyUv34448a+xb9/axcuVLr+MGDB6vy8vLU448ePVK5urqq5syZo3XOlxV9Rp9++ukr9xsxYoSqZcuWqoSEBPWYUqlUzZo1S+Xk5KT65ZdfVCqVSpWQkKBycnJSbdiw4ZXzDRkyRNWvX79S4yOi6oflN0RUo1laWmLYsGFa41KpVL2qWFBQgIyMDKSlpeGtt94CgGLLX4rTs2dPje46IpEIHTp0gEwmg1wuL9Mc48aN03jdsWNHAMC9e/fUY6dOnYKenh7Gjh2rse/w4cNhZmZWpvMolUrMnj0bN27cwJEjR9C1a1e8//77OHjwoMZ+ixYtgqura5lq7AMDA1FYWIioqCj1WGJiIv744w/06NFDfaNyRX3e/xQbGwuVSoXx48dr1Li7urqic+fOWvsbGxur/z8vLw/Pnj1Deno6OnfujOzsbNy5c0fnGIocP34cderUwYgRIzTGR4wYgTp16uDEiRNax4wePVqj5Klu3bpo2rQp7t69W+44/ik1NRW///47evToARcXF/W4SCTCO++8o44bgPpn6Ny5c0hNTS1xTlNTUzx+/BgXLlyokBiJqOqw/IaIarSGDRuWeFPjjh07sHv3bty+fRtKpVJjW0ZGRpnnf5mlpSUAID09HSYmJjrPUVTukZ6erh5LSkqCnZ2d1nxSqRQODg7IzMws9TyxsbE4e/Ysli1bBgcHB6xevRozZszABx98gIKCAnWJxc2bN+Hu7l6mGvs+ffrA3NwcERERmDx5MgAgPDwcANSlN0Uq4vP+pwcPHgAAmjVrprXN0dERZ8+e1RiTy+VYu3Ytjhw5gpSUFK1jyvIZliQpKQlubm7Q19f8Z1NfXx9NmjTB9evXtY4p6Wfn4cOH5Y7j5ZgAoHnz5lrbmjVrBrFYrP4M7e3tMXXqVGzYsAE+Pj5o2bIlOnbsCD8/P3h4eKiPe/fddzF9+nSMGTMGdnZ2aN++Pbp3746+ffvqdE8GEVU9JvVEVKMZGRkVO/7999/jv//9L3x8fDB27FjY2dlBIpHg8ePHmDdvHlQqVZnmf1UXlNedo6zHl1XRjZ3t2rUD8OILwdq1a/HOO+9g/vz5KCgogIuLCy5fvowlS5aUaU4DAwP4+/tj586duHTpEjw9PXHgwAHUq1cPXbp0Ue9XUZ/363jvvfdw+vRpBAUFoV27drC0tISenh7OnDmDH374QeuLRmWrqvacZTVnzhwEBgbi9OnTuHDhAsLCwrB582a8/fbb+M9//gMA8PLywvHjx3H27FmcO3cO586dw6FDh7B+/Xrs3LlT/YWWiKofJvVEVCvt378f9vb22Lhxo0Zy9dNPPwkYVcns7e0RFxcHuVyusVqvUCiQlJRUpgckFb3Phw8fon79+gBeJPbr1q3D1KlTsWjRItjb28PJyQlDhgwpc2yBgYHYuXMnIiIikJGRAZlMhqlTp2p8rpXxeRetdN+5cweNGjXS2JaYmKjxOjMzE6dPn8bgwYOxePFijW2//PKL1twikUjnWP766y8UFBRorNYXFBTg7t27xa7KV7aisrDbt29rbbtz5w6USqVWXA0bNkRwcDCCg4ORl5eHiRMnYtOmTZgwYQKsra0BACYmJujbty/69u0L4MVvYBYvXoywsDC8/fbblfyuiKi8qtcyAhFRBRGLxRCJRBorxAUFBdi4caOAUZWsR48eKCwsxLZt2zTG9+7di6ysrDLN0a1bNwAvuq78s17ewMAAK1asgLm5OZKSktC3b1+tMpJXcXV1RcuWLREdHY0dO3ZAJBJp9aavjM+7R48eEIlE+P777zXaM167dk0rUS/6IvHybwSePHmi1dIS+Lv+vqxlQb169UJaWprWXHv37kVaWhp69epVpnkqkrW1Nby8vHDq1CncunVLPa5SqbBhwwYAQO/evQG86N7zcktKAwMDdWlT0eeQlpamdR5XV1eNfYioeuJKPRHVSn5+fvj6668xadIk9O7dG9nZ2Th06JBOyWxVGj58OHbv3o1Vq1bh/v376paWMTExaNy4sVZf/OJ07twZgYGBCAsLw4ABAzB48GDUq1cPDx48wP79+wG8SNC++eYbODo6ol+/fmWOLzAwEJ999hl+/vlntG/fXmsFuDI+b0dHR4wZMwY//vgjQkJC0KdPH6SmpmLHjh1wcXHRqGM3NTVF586dceDAARgaGsLd3R0PHz7Enj174ODgoHH/AgB4enoCAJYvX46BAwfCwMAALVq0gJOTU7GxvP3224iJicHixYtx/fp1tGzZEgkJCQgLC0PTpk0rbQX76tWrWLdunda4vr4+Jk+ejAULFiA4OBhjxozB6NGjYWtri1OnTuHs2bPw9/dHp06dALwozVq0aBH69OmDpk2bwsTEBFevXkVYWBg8PT3VyX3//v3RunVreHh4wM7ODjKZDHv37oVEIsGAAQMq5T0SUcWonv+6ERG9pokTJ0KlUiEsLAxLliyBra0t+vXrh4CAAPTv31/o8LRIpVJs3boVS5cuRWxsLI4cOQIPDw/88MMPWLBgAXJzc8s0z5IlS9C+fXvs3r0bmzdvhkKhgL29Pfz8/DBhwgRIpVKMGDEC//nPf2BmZgYfH58yzTtw4EAsXboUeXl5WjfIApX3eS9YsAA2NjbYu3cvli5diiZNmuCjjz7CvXv3tG5OXbZsGb7++mucPHkSkZGRaNKkCebMmQN9fX3Mnz9fY19vb2+8//772L17NxYtWoSCggLMmDGjxKTezMwMu3btwpo1a3Dy5ElERETA2toaI0eOxMyZM3V+inFZXb58udjOQVKpFJMnT4a7uzt2796NNWvWYNeuXXj+/DkaNmyI999/HxMmTFDv7+zsjN69e+P8+fM4ePAglEol6tevjylTpmjsN2HCBJw5cwbbt29HVlYWrK2t4enpiSlTpmh02CGi6kekqoq7l4iIqFwKCwvRsWNHeHh4lPsBTkREVPuxpp6IqJoobjV+9+7dyMzMLLYvOxERURGW3xARVRMLFy5Efn4+vLy8IJVK8fvvv+PQoUNo3LgxgoKChA6PiIiqMZbfEBFVE1FRUdixYwfu3r2L58+fw9raGt26dcPs2bNhY2MjdHhERFSNMaknIiIiIqrhWFNPRERERFTDMaknIiIiIqrheKOsjp49k0OpLL1iydraFKmp2VUQERHxeiOqOrzeiCqfWCyClZWJTscwqdeRUqkqU1JftC8RVQ1eb0RVh9cbUfXD8hsiIiIiohqOST0RERERUQ3HpJ6IiIiIqIZjUk9EREREVMMxqSciIiIiquHY/YaIiIioAuTkyJGdnYHCQoXQoVA1pqcngampBYyMdGtZWRom9URERESvSaHIR1bWM1ha2kAiMYBIJBI6JKqGVCoVFIo8pKc/hb6+BBKJtMLmFrT8Jj8/H8uWLYOPjw88PDwQFBSEuLi4Uo8LDQ2Fs7Oz1p/OnTu/8rjLly/DxcUFzs7OyMzMrKi3QURERG+4rKx0mJpaQCo1ZEJPJRKJRJBKDWFiYoHs7PQKnVvQlfp58+bh2LFjGDt2LBo3bozIyEhMmjQJ27dvh5eXV6nHL168GIaGhurX//z/l6lUKnz++ecwMjLC8+fPKyR+IiIiIgAoKMiHgUEdocOgGsLQ0AhyeUaFzilYUh8fH4/Dhw9j/vz5GDduHABgyJAh8Pf3x/Lly7Fjx45S5+jXrx/Mzc3LdL7IyEjcv38fAQEB2L59++uE/kpx1x4h4kwi0jLzUMfcAMO6OaKTa71KOx8REREJT6kshFisJ3QYVEOIxXpQKgsrds4KnU0HMTExkEgkGD58uHrMwMAAgYGBuHjxIp48eVLqHCqVCtnZ2VCpXv246uzsbKxYsQIzZsyAhYXFa8dekrhrj7D1yA2kZuZBBSA1Mw9bj9xA3LVHlXZOIiIiqh5YdkNlVRk/K4Il9QkJCWjatClMTDTv/PXw8IBKpUJCQkKpc3Tv3h3e3t7w9vbG/PnzkZ5efG3SunXrYGpqilGjRlVI7CWJOJOI/AKlxlh+gRIRZxIr9bxERERE9GYTrPxGJpOhbt26WuO2trYA8MqVenNzcwQHB8PT0xMSiQS//vor9uzZg+vXr2Pfvn2QSv++k/ju3bvYtm0bQkNDoa9fuW83NTNPp3EiIiKiN92MGZMBAGvXbqjSY2sbwZL63NxcSCQSrXEDAwMAQF5eyYlwSEiIxms/Pz+0aNECixcvRlRUFIKCgtTbvvzyS7Rr1w6+vr4VEre1tWmJ22ytjCB7lqM9bmkEW1uzCjk/ERWP1xhR1eH1pu3JEzH09WvXMz07dmxTpv0iIg6hQYMG5T5PUSlKeT6/1zlWaGKxuEKvJcGSekNDQygU2g9nKErmi5L7sho1ahSWLVuGuLg4dVL/008/4eeff0ZkZOTrB/z/UlOzoVQWX8M/xKcpth65oVWC09DWBDJZVoXFQESabG3NeI0RVRFeb8VTKpUoeOnf/5pu0aLFGq/37t2Fx49TMHPmuxrjZmYWr/XeV6xYCwDlmuN1jhWaUqks8VoSi0WvXEgujmBJva2tbbElNjKZDABgZ2en03xisRh169ZFRsbf7YGWLVuGHj16wMTEBElJSQCg7k+fnJyM3Nxcnc/zKkVdbv7Z/cba3BCX/nyK8wmP0b6ldrkRERERUXXUt29/jdenT8ciIyNda/xlubm5r2wz/rLiKjeq4tjaRrCk3sXFBdu3b4dcLte4Wfby5cvq7bpQKBRISUmBm5ubeiwlJQW3bt3C8ePHtfYfPHgwPD09sXfv3nK+g+J1cq2HTq711CsZigIllu3+HVsOJ8DOyghN6pWtBScRERFRdTdjxmRkZ2fjgw8+RGjoSty8eQNjxozFxIlT8PPPp3HgQCRu3bqJzMwM2NraoX//gQgOHg89PT2NOYC/6+IvXbqAWbOmYsmSpfjrrzuIigpHZmYG3N098Z//fAgHh4YVciwAhIfvxe7dO5Ca+hSOjo6YMWMONm5crzFnTSFYUu/n54ctW7Zg37596j71+fn5iIiIQJs2bdQ30SYnJyMnJweOjo7qY9PS0lCnjuYDHjZv3oy8vDx06dJFPbZ8+XIUFBRo7Hf48GFER0dj2bJlqF+/fiW9u79J9MWYMdQdn239DaHhV7AopC0sTXUrLSIiIqI3T9Gzb1Iz82BdjZ99k57+DB98MAd9+vjBz28A6tZ9EWN09CEYGRljxIgxMDY2wsWLF7Bp07eQy+WYPn12qfNu3boZYrEeRo8ei6ysTOzatR2ffroQGzdurZBjIyPDsHLlUrRu3QYjRoxCSkoK5s9/H2ZmZrC1rbhKjqoiWFLv6ekJPz8/LF++HDKZDI0aNUJkZCSSk5Px5ZdfqvebO3cuzp8/j5s3b6rHfH190b9/fzg5OUEqleLcuXM4evQovL294e/vr96ve/fuWuctapXZvXv3Mj+46nWZm0gxK9ATX2y/iNDweMwd3QZSCR9QQURERMUrevZN0X16Rc++AVDtEvunT2WYN28R/P0Ha4x/8snnMDD4uwxnyJBALFv2BSIj92HSpHc0uhUWp6CgAFu2bFV3LzQ3t8Dq1ctx585tNGvW/LWOVSgU2LRpPVxd3bFq1Tr1fs2bt8CSJZ8wqdfV0qVLsWrVKuzfvx8ZGRlwdnbGhg0b4O3t/crjBg4ciEuXLiEmJgYKhQL29vaYNm0apkyZUultK8uroZ0pJg9shbURV/DDkRuYNLAVH1JBRERUy/3vSgrOxqfofFxicgYKCjUbc+QXKPF9dAJ++iNZ5/l8POqjs3vlVCgYGhrCz2+A1vg/E/rnz+XIz1fA09ML+/dH4N69u2jRwumV8w4YMEgjr/P0bA0ASE5+WGpSX9qxN25cR0ZGBqZNG6qxX+/eflizZsUr566uBM2ADQwMMHfuXMydO7fEfbZv36419vnnn5f7nDNnzsTMmTPLffzr8HKyxbBuzRB+5g7sbU0woFMTQeIgIiKi6u3lhL60cSHZ2toVu6h6504iNm5cj0uXfoNcLtfYJpdnlzpvURlPETOzFxUWWVmld18q7dhHj1580Xq5xl5fX79KyrMrQ/Vc1q7F+ndsjIcyOcLP3EF9axO0cbIVOiQiIiKqJJ3dy7dC/p91/yv24ZXW5gaYO6Zs/eOryj9X5ItkZWVh5szJMDY2xcSJU2Fv7wCpVIpbt25g/fpQKJWlt6AUi4svVVapSv9i8zrH1lQ1r1N/DScSiTCunwua1jfHxoPXcf8xe/0SERGRpmHdHCF96YFKUn0xhnVzLOGI6uX33y8iIyMDCxZ8jKCgUejcuQvateugXjEXWr16L75oJSU90BgvKChASoru5VLVAZN6AUglepgZ4A5jQ32EhscjU54vdEhERERUjXRyrYeQfi6wNn/RMc/a3AAh/Vyq3U2yJRGLX6SY/1wZVygUiIzcJ1RIGlxcWsHCwgIHDkRqdEo8fjwGWVmZAkZWfiy/EYilqQFmBrjjvz9ewtrIK/jPSC9IauAjjomIiKhyFD37piZyd/eAmZk5liz5BIGBIyASiXD0aDSqS/WLRCLBhAmTsXLlMvz739Pg69sTKSkpOHLkIOztHWpkMxNmkQJqUs8cE/1b4XZSBrYdvVGr67yIiIjozWFhYYmlS1fC2toGGzeux65dP6Jt2w6YNm2W0KGpBQSMwL///T4ePUrBN9+sxuXLv+O//10BU1MzSKU175lCIhUzSZ2kpmZDqSz9Iyt6omxZRP18Bwf+dxdBvs3h16HR64ZI9MbR5XojotfD6614jx7dQ716jYUOg16TUqmEv39vdOvmi7lzF1bquV71MyMWi2BtbarTfFyprwYG+TRFWxc77Dt1G/GJT4UOh4iIiKjWy8vT7i4UE3MYmZkZ8PJ69TOTqiPW1FcDYpEIEwe0hOxZDr7dfw0LxraFvY2J0GERERER1Vrx8X9g/fpQdO/eA+bmFrh16wYOHz6AZs0c4evbS+jwdMaV+mrC4P874hhI9LAm7DKynrMjDhEREVFladDAHjY2tggL24NVq5bh7Nmf4Oc3AKtXr4dEIhE6PJ2xpl5HlVFT/0+JyRn4asfvcGxgjvdGtoa+Hr93EZWGNb5EVYfXW/FYU0+6Yk19LefYwALj+7vg5oN07Dh+ix1xiIiIiKhUrKmvhjq51kPyUzkOx92Dg60peno7CB0SEREREVVjXKmvpoZ2bQavFjbYdeJPXPsrTehwiIiIiKgaY1JfTYlFIrzt3woNbIyxLuoqUlLlQodERERERNUUk/pqzMhAH7MCPaCvJ8Ka8CuQ5yqEDomIiIiIqiEm9dWcjYURpg91x9P0HHwbdRWFSqXQIRERERFRNcOkvgZwamiJsX2dce3uM+yOvS10OERERERUzTCpryG6eDZAn3YNEXsxCad/fyh0OEREREQ6iY4+CB+ftkhJSVaPBQYOxJIln5Tr2Nd16dIF+Pi0xaVLFypsTiExqa9Bgnybw72ZNXYcv4Ub954JHQ4RERHVYh98MAe9evkgJyenxH3efXcG+vbthry8vCqMTDcnThzF3r07hQ6j0jGpr0HEYhGmDHKFnZURvom8gifpJV9kRERERK+jd+++yM3NxdmzZ4rd/uxZGi5e/A1du/rCwMCgXOfYuTMcc+cufJ0wSxUbewx79+7SGm/dug1iY/+H1q3bVOr5qwqT+hrG2PBFRxwAWBMWj5y8AoEjIiIiotqoS5fuMDIyxokTR4vdfvLkCRQWFqJPH79yn0MqlUJfX5hnoYrFYhgYGEAsrh3pMJ8oWwPVtTLGtKHuWLHnD3x34BpmBXhALBYJHRYRERHVIoaGhujSpRtOnTqBzMxMmJuba2w/ceIorK2t0bBhYyxf/l9cvHgejx8/hqGhIdq0aYvp02ejfv0GrzxHYOBAeHl5Y8GCT9Rjd+4kYtWqZbh69QosLCwwePAw2NjYah3788+nceBAJG7duonMzAzY2tqhf/+BCA4eDz09PQDAjBmT8ccflwAAPj5tAQD16tVHWNhBXLp0AbNmTcWaNd+iTZu26nljY4/hxx9/wL17d2FsbILOnbvgnXdmwdLSUr3PjBmTkZ2djY8+WowVK5YiIeEazMzMMXz4SIwZE6LbB11BmNTXUC0bW2FMbydsO3oTYacTEdSjudAhERERUQU6/+gSDiTG4FleOqwMLDHI0Q/t61VtqUjv3n44duwITp+OxaBBQ9Xjjx6l4OrVeAQGjkRCwjVcvRqPXr36wtbWDikpyYiKCsfMmVPw44/7YGhoWObzpaY+xaxZU6FUKvGvf4XA0NAIBw5EFlveEx19CEZGxhgxYgyMjY1w8eIFbNr0LeRyOaZPnw0ACAmZgJycHDx+nIKZM98FABgZGZd4/ujog/jii0/h6uqOd96ZhSdPHiM8fA8SEq5h48ZtGnFkZmbgvfdmwde3J3r27INTp05g/fpQNGvWHJ06dS7ze64oTOprsO5e9ngokyPm/H00sDGBj0d9oUMiIiKiCnD+0SXsvBEOhfLFgyef5aVj541wAKjSxL5duw6wtLTCiRNHNZL6EyeOQqVSoXfvvnB0bA5f314ax3Xu3BVTp47H6dOx8DnwocEAACAASURBVPMbUObz7dixFRkZ6di0aTucnV0AAP36+WPUqKFa+37yyecwMPj7C8OQIYFYtuwLREbuw6RJ70AqlaJdu46IiNiHjIx09O3b/5XnLigowPr1oWje3Amhod9BKpUCAJydXfDJJwtw8GAkAgNHqvd/8uQxPv74c/Tu/aL8yN9/MAID/XH48H4m9aS7kb2aIyVNjm1Hb6BuHSO0cLAs/SAiIiKqEudSLiIu5Tedj/sr4z4KVJr3zSmUCuxICMMvyed1nq9T/XboUN9b5+P09fXRo0cvREWF4+nTp7CxsQEAnDhxDA4ODdGqlZvG/gUFBZDLs+Hg0BCmpma4deuGTkl9XNz/4O7uqU7oAcDKygq9e/dDZOQ+jX3/mdA/fy5Hfr4Cnp5e2L8/Avfu3UWLFk46vdcbN67j2bM09ReCIj169MY336zGL7/8TyOpNzU1Ra9efdWvJRIJWrZ0RXKyMK3HmdTXcHpiMd4Z4obPt17A2ogrWBTSFjYWRkKHRURERK/h5YS+tPHK1Lu3HyIi9uHkyWMIChqNu3f/wu3btzB+/CQAQF5eLrZv/wHR0Qchkz2BSqVSH5udna3TuR4/fgR3d0+t8UaNGmuN3bmTiI0b1+PSpd8gl8s1tsnlup0XeFFSVNy5xGIxHBwa4vHjFI1xO7u6EIk072k0MzNHYqIwDwplUl8LmBhKMCvQA59vu4g1YVfwYXAbGEr5V0tERCS0DvW9y7VCvvB/X+BZXrrWuJWBJf7dZmpFhFZm7u6eqF/fHsePxyAoaDSOH48BAHXZycqVyxAdfRDDh4+Cm5s7TE1NAYjwyScfaiT4FSkrKwszZ06GsbEpJk6cCnt7B0ilUty6dQPr14dCqVRWynn/SSzWK3a8st5zaWpHDx9CfWsTvDPEFQ+fZmPjwetQCvQDRURERK9vkKMfJGKJxphELMEgx/K3j3wdvXr1QULCdSQlPUBs7DE4O7dUr2gX1c3PnDkHvr690K5dR3h4tNZ5lR4A6tath6SkB1rj9+/f03j9++8XkZGRgQULPkZQ0Ch07twF7dp1gJmZudaxQNk6BNarV7/Yc6lUKiQlPUDdutX73kUm9bWIW1NrjOzZAr//+RSRP90ROhwiIiIqp/b12mC0SwCsDF7cK2dlYInRLgFV3v2mSJ8+/QAAa9euRFLSA43e9MWtWIeH70FhYaHO5+nUqTOuXLmMmzdvqMeePXuG48ePaOxX1Fv+n6viCoVCq+4eAIyMjMr0BcPFpRWsrOogKioMCoVCPX7qVCxksid4662qv/lVF6zRqGV6eTvgoUyOw3H3YG9jgo6u9YQOiYiIiMqhfb02giXxL2vatBmaN3fC2bM/QSwWo2fPv28QfestHxw9Gg0TE1M0adIU165dwYUL52FhYaHzeUaPDsHRo9F4993pCAwcCQMDQxw4EIm6desjO/tP9X7u7h4wMzPHkiWfIDBwBEQiEY4ejUZxhQrOzi44duwIQkNXwMWlFYyMjOHj01VrP319fbzzzkx88cWnmDlzCnr16oMnTx4jLGwPmjVzxMCB2h14qhMm9bWMSCTCv/o44XHac2yJvgE7K2M0a1Dcr6KIiIiIyq5PHz/cvn0LXl7e6i44ADB79vsQi8U4fvwI8vLy4e7uiVWrvsG7787U+Rw2NjZYs+Y7rFy5FNu3/6Dx8Kn//vcz9X4WFpZYunQl1q5dhY0b18PMzBx9+vRD27bt8e67MzTmHDw4ALdu3UB09CHs2bMT9erVLzapB4D+/QdCKpVix46t+Oab1TAxMUHv3n6YOnVmsb3yqxORSqhq/hoqNTUbSmXpH5mtrRlksqwqiKh4Wc/z8dnWC1AUKLEopC3qmJf9wQ9ENY3Q1xvRm4TXW/EePbqHevW0O7QQleRVPzNisQjW1qY6zcea+lrKzFiK2YEeyFUUIjTiCvIUute1EREREVHNIGhSn5+fj2XLlsHHxwceHh4ICgpCXFxcqceFhobC2dlZ60/nzpo3MKSkpCA0NBSBgYFo164dOnTogODg4DKdozawtzXFlEGuuP8oC5sPJwjWYomIiIiIKpegNfXz5s3DsWPHMHbsWDRu3BiRkZGYNGkStm/fDi8vr1KPX7x4MQwN/y4r+ef/A0BsbCw2bdqEXr16YejQoSgoKMD+/fsxbtw4fPXVVxgyZEiFv6fqpnVzGwz3bY69p27joI0JBvk0FTokIiIiIqpggiX18fHxOHz4MObPn49x48YBAIYMGQJ/f38sX74cO3bsKHWOfv36wdy85JtAO3TogFOnTqFOnTrqsVGjRmHw4MFYs2bNG5HUA0Df9g3xUJaNqLN/oYGNCdq62AkdEhERERFVIMHKb2JiYiCRSDB8+HD1mIGBAQIDA3Hx4kU8efKk1DlUKhWys7NLLCtp0aKFRkIPAFKpFN26dcPDhw+Rm5v7em+ihhCJRBjr5wJHe3NsOnQd9x7xBiciIiKi2kSwpD4hIQFNmzaFiYmJxriHhwdUKhUSEhJKnaN79+7w9vaGt7c35s+fj/R07ccpF0cmk8HY2LjatyaqSBJ9MWYM84CZsQRrwuORnp0ndEhEREREVEEES+plMhns7LTLQGxtbQHglSv15ubmCA4OxuLFi7F69WoMGjQIUVFRCAkJQX5+/ivPe+/ePRw/fhx+fn4Qicr22ODawsJEipkBHpDnKrA24goUBeyIQ0RERFQbCFZTn5ubC4lEojVetHqel1fySnJISIjGaz8/P7Ro0QKLFy9GVFQUgoKCij0uJycHs2fPhpGREebMmVOuuHXpGWpra1auc1QmW1szvD8G+OKH37DrVCLeHdXmjftyQ7VTdbzeiGorXm/anjwRQ09PxH9TqUxUKhXEYnGFXkuCJfWGhoZQKBRa40XJvK6lMaNGjcKyZcsQFxdXbFJfWFiIOXPmIDExEZs3by72twRlUVMePvUqzeuZYWjXZoj86Q6sTaUY0KmJ0CERvZbqfL0R1Ta83oonEomRk5MLqfTNKe2l8svPz4NIJC7xWqpRD5+ytbUttsRGJpMBgM5Jt1gsRt26dZGRkVHs9oULF+LMmTP46quv0L59e90DrmX8OzVGh1Z1EXHmDn6/JRM6HCIiohrN1NQS6eky5Ofn8bkwVCKVSoX8/Dykp8tgampZoXMLtlLv4uKC7du3Qy6Xa9wse/nyZfV2XSgUCqSkpMDNzU1r21dffYWIiAgsXLgQ/fv3f73AawmRSITx/Vzw5NlzbDh4HR8Ge6OhnW7fCImIiOgFI6MXuUxGxlMUFhYIHA1VZ3p6+jAzs1L/zFQUwZJ6Pz8/bNmyBfv27VP3qc/Pz0dERATatGmDunXrAgCSk5ORk5MDR0dH9bFpaWlarSo3b96MvLw8dOnSRWN806ZN2LJlC6ZOnYrg4ODKfVM1jFSihxnDPPDZ1t+wJiwei0LawtxEKnRYRERENZKRkUmFJ2pEZSVYUu/p6Qk/Pz8sX74cMpkMjRo1QmRkJJKTk/Hll1+q95s7dy7Onz+Pmzdvqsd8fX3Rv39/ODk5QSqV4ty5czh69Ci8vb3h7++v3u/48eNYtmwZmjRpgmbNmmH//v0aMfTu3RvGxsaV/2arMSszA8wM8MB/d1zCN5FX8P5IL0j0BavKIiIiIqJyECypB4ClS5di1apV2L9/PzIyMuDs7IwNGzbA29v7lccNHDgQly5dQkxMDBQKBezt7TFt2jRMmTIF+vp/v6UbN24AAO7evYsPPvhAa57Y2Ng3PqkHgKb1zTFxQEt8u/8ath+9ifH9XXj3PhEREVENIlLxbg6d1IbuNyWJ+vkODvzvLkb2aI4+7RsJHQ5RmdXE642opuL1RlT5alT3G6p+Bvk0hbezLfacuo34xFShwyEiIiKiMmJST2pikQhvD2iFhram+O7AVTx8Khc6JCIiIiIqAyb1pMFAqodZgR6Q6OshNCwe2TnaDwgjIiIiouqFST1pqWNuiJnD3JGWlYd1kVdQUKgUOiQiIiIiegUm9VQsR3sLjOvnjBv307HzxJ98Oh4RERFRNSZoS0uq3t5yq4+HT+U48ut92NuYoKe3g9AhEREREVExuFJPrxTQ1RGtm9tg14k/ce1umtDhEBEREVExmNTTK4nFIkwa2Ar1bYyxPvIqHqc9FzokIiIiInoJk3oqlZGBPmYFeEAsFmF1WDye57IjDhEREVF1wqSeysTW0gjTh7pBlp6D9fuvoVDJjjhERERE1QWTeioz50ZWCO7rjGt/pWHPydtCh0NERERE/4/db0gnXT0bIPmpHMd+ewB7GxN0a20vdEhEREREbzyu1JPOhvs6wq1ZHfx47BZu3n8mdDhEREREbzwm9aQzPbEYUwe5wc7KCN9EXsWT9ByhQyIiIiJ6ozGpp3IxNnzREUelUiE0LB45eQVCh0RERET0xmJST+VWt44xpg1xQ0rqc2w4cA1KpUrokIiIiIjeSEzq6bW0bFIHY3q3wOXEVISdSRQ6HCIiIqI3Ervf0GvzbeOApKdyxJy7D3sbE3R2ry90SERERERvFK7UU4UY1bMFWja2wtaYG7idlCF0OERERERvFCb1VCH09cR4Z4gb6pgbYm1EPFIzcoUOiYiIiOiNwaSeKoypkQSzAz2gKFRhTXg8cvPZEYeIiIioKjCppwpV39oEUwe7IkmWjU2HEqBUsSMOERERUWVjUk8Vzr2ZNUb0aIFLt2SI+vkvocMhIiIiqvXY/YYqRe+2Dkh+mo1Dv9xFAxtjdGxVT+iQiIiIiGotrtRTpRCJRPhXH2c4OVjg++gbuJOcKXRIRERERLUWk3qqNPp6Ykwb5g4LEylCI+LxLCtP6JCIiIiIaiUm9VSpzI2lmBXogdz8QoSGxyNPUSh0SERERES1DpN6qnQOtqaYMtAV9x5l4fvoBKjYEYeIiIioQjGppyrRuoUNArs74nzCExz85a7Q4RARERHVKux+Q1XGr0MjJMnkiPr5LzSwNkFbFzuhQyIiIiKqFbhST1VGJBJhXD9nODYwx6bD13HvUZbQIRERERHVCkzqqUpJ9PUwY5g7TI0kCI2IR0Y2O+IQERERvS4m9VTlLEwNMHOYB7JzFFgbcQWKAnbEISIiInodTOpJEI3rmeHtAa2QmJyJH47cZEccIiIiotcgaFKfn5+PZcuWwcfHBx4eHggKCkJcXFypx4WGhsLZ2VnrT+fOnYvdf9++fejXrx/c3d3Rt29f7Nixo6LfCpVDWxc7DOnSFHHXHiHm3H2hwyEiIiKqsQTtfjNv3jwcO3YMY8eORePGjREZGYlJkyZh+/bt8PLyKvX4xYsXw9DQUP36n/9fZPfu3fj444/h5+eH8ePH48KFC1i8eDHy8vIwYcKECn0/pLuBbzVB8lM5wk4nor61CVq3sBE6JCIiIqIaR7CkPj4+HocPH8b8+fMxbtw4AMCQIUPg7++P5cuXl2k1vV+/fjA3Ny9xe25uLlauXImePXti9erVAICgoCAolUqsXbsWw4cPh5mZWYW8HyofkUiECf1b4smzHHx38BoW/MsbDnamQodFREREVKMIVn4TExMDiUSC4cOHq8cMDAwQGBiIixcv4smTJ6XOoVKpkJ2dXWI99rlz55Ceno7Ro0drjI8ZMwZyuRw//fTT670JqhBSiR5mBnjAUKqHNeHxyHyeL3RIRERERDWKYEl9QkICmjZtChMTE41xDw8PqFQqJCQklDpH9+7d4e3tDW9vb8yfPx/p6eka269fvw4AcHNz0xh3dXWFWCxWbyfhWZkZYFaABzLk+VgXcQUFhUqhQyIiIiKqMQQrv5HJZKhbt67WuK2tLQC8cqXe3NwcwcHB8PT0hEQiwa+//oo9e/bg+vXr2LdvH6RSqfocUqkUlpaWGscXjZXltwFUdZrWN8eE/i3x3YFr2H70Jsb1c4FIJBI6LCIiIqJqT7CkPjc3FxKJRGvcwMAAAJCXV/JDiUJCQjRe+/n5oUWLFli8eDGioqIQFBT0ynMUnedV5yiJtXXZ671tbVmvryv/bmZIf67AnhO34NzUGoO7OgodEtUQvN6Iqg6vN6LqR7Ck3tDQEAqFQmu8KNEuSu7LatSoUVi2bBni4uLUSb2hoSHy84uvz87Ly9P5HACQmpoNpbL0nuq2tmaQybJ0np+A3t72+PP+M2w+cBVmBnpwb2YtdEhUzfF6I6o6vN6IKp9YLNJpIRkQsKbe1ta22PIXmUwGALCzs9NpPrFYjLp16yIjI0PjHAqFQqvWPj8/H+np6Tqfg6qGWCTC2/4t4WBrim/3X0VKqlzokIiIiIiqNcGSehcXF/z111+QyzUTtsuXL6u360KhUCAlJQVWVlbqsZYtWwIArl69qrHv1atXoVQq1dup+jGU6mNWgAckemKsDotHdo72b3WIiIiI6AXBkno/Pz8oFArs27dPPZafn4+IiAi0adNGfRNtcnIyEhMTNY5NS0vTmm/z5s3Iy8tDly5d1GMdO3aEpaUldu7cqbHvrl27YGxsjK5du1bkW6IKZm1hiBnDPJCWmYv1UVfZEYeIiIioBILV1Ht6esLPzw/Lly+HTCZDo0aNEBkZieTkZHz55Zfq/ebOnYvz58/j5s2b6jFfX1/0798fTk5OkEqlOHfuHI4ePQpvb2/4+/ur9zM0NMSsWbOwePFizJ49Gz4+Prhw4QIOHDiA999//5UPrqLqobmDBUL8XLD5cAJ2xf6J4D7OQodEREREVO0IltQDwNKlS7Fq1Srs378fGRkZcHZ2xoYNG+Dt7f3K4wYOHIhLly4hJiYGCoUC9vb2mDZtGqZMmQJ9fc23NGbMGEgkEmzZsgWxsbGoX78+FixYgLFjx1bmW6MK1Nm9Ph4+lSPm3H3Y25igRxsHoUMiIiIiqlZEqpIex0rFYvcbYSiVKoSGx+PKnTS8N8ITLZvUETokqkZ4vRFVHV5vRJWvRnW/IdKFWCzC5EGuqG9tjHVRV/E47bnQIRERERFVG0zqqcYwMtDHzEAPiEQirA6Lx/NcdsQhIiIiApjUUw1jZ2mE6UPdIEvPwbf7r6FQyY44REREREzqqcZxbmSF4L7OuPpXGvadSiz9ACIiIqJaTtDuN0Tl1dWzAZJk2Tj22wM0sDFBV88GQodEREREJBiu1FONNaJHc7g2rYPtR2/i5v1nQodDREREJBgm9VRj6YnFeGewK2wtjfBN5FXI0nOEDomIiIhIEEzqqUYzNpRgdqAHVCoV1oTHIyevQOiQiIiIiKock3qq8erWMcbUIW5IefocGw9eL9PDwYiIiIhqEyb1VCu4NqmDUb1a4I/bTxH+EzviEBER0ZuF3W+o1ujRxh4Pn8px5Nf7sLcxwVtu9YUOiYiIiKhKcKWeag2RSITRvVrApZElfjhyA4kPM4QOiYiIiKhKMKmnWkVfT4xpQ91Rx8wQoRFXkJqRK3RIRERERJWOST3VOqZGEswK9ICioBCh4fHIyy8UOiQiIiKiSsWknmqlBjYmmDLIDQ9k2dh0+DqUKnbEISIiotqLST3VWh6O1hjh2xwXb8pw4OxfQodDREREVGnY/YZqtd7tGiLpqRwH/ncXDWxM0L5lXaFDIiIiIqpwXKmnWk0kEiG4jzNaOFhg8+EE/JWSKXRIRERERBWOST3VehJ9MaYPdYe5sRSh4fF4lpUndEhEREREFYpJPb0RzE2kmB3ogZz8QqyNiEe+gh1xiIiIqPZgUk9vDAc7U0we2Ap3U7KwJToBKnbEISIiolqCST29Ubxa2GJYt2Y4n/AEh+LuCR0OERERUYVg9xt64/Tv2BjJT+WI/OkOGlibwNvZVuiQiIiIiF4LV+rpjSMSiTCunwuaNTDHxkPXcP9xltAhEREREb0WJvX0RpLo62HmMHeYGEqwJjweGfJ8oUMiIiIiKjcm9fTGsjA1wKwAD2Q/V2BtRDwUBUqhQyIiIiIqFyb19EZrXM8Mb/u3QuLDTGyNucGOOERERFQjMamnN15bFzsM8WmKX64+wtHzD4QOh4iIiEhnFdL9pqCgALGxscjIyICvry9sbdlNhGqWgZ2b4OFTOfaduo161sZo3dxG6JCIiIiIykznpH7p0qU4d+4cwsPDAQAqlQrjx4/HhQsXoFKpYGlpib1796JRo0YVHixRZRGJRJgwoCWePMvBdweuYUGwNxxsTYUOi4iIiKhMdC6/+fnnn9G2bVv165MnT+K3337DxIkT8fXXXwMANmzYUHERElURA4keZga4w1CqhzVh8ch6zo44REREVDPonNQ/evQIjRs3Vr8+deoUHBwc8P7772PAgAEYOXIk4uLiKjRIoqpSx9wQM4d5ID07H+sir6KgkB1xiIiIqPrTOalXKBTQ1/+7aufcuXN466231K8bNmwImUxWMdERCaBZA3NM6O+Cmw/S8eOxW+yIQ0RERNWezkl9vXr18PvvvwMA/vzzTzx48ADt2rVTb09NTYWxsXHFRUgkgI6u9TCgU2P8dDkZJy4mCR0OERER0SvpfKPsgAEDsG7dOqSlpeHPP/+EqakpunXrpt6ekJBQ5ptk8/PzsXr1auzfvx+ZmZlwcXHBnDlz0KlTJ51imjRpEn766SeMHTsWCxYs0NiWlZWFdevWITY2Fo8ePYKNjQ18fHwwffp01K1bV6fz0JtlaNdmSH4qx+7YP1Hf2hhuTa2FDomIiIioWDqv1E+ZMgVDhw7FH3/8AZFIhK+++grm5uYAXiTQJ0+eLHNSPm/ePGzduhWDBg3CggULIBaLMWnSJPVvAsri9OnTuHDhQrHblEolJk6ciN27d6NXr15YtGgR/Pz8cPDgQQQHByM/nzdCUsnEIhEmDWwFextTrI+6hpRUudAhERERERVLpKrAgmGlUgm5XA5DQ0NIJJJX7hsfH4/hw4dj/vz5GDduHAAgLy8P/v7+sLOzw44dO0o9X35+PgYOHIiBAwciNDRUa6X+8uXLCAoKwkcffYQxY8aox3/88Ud89tln2Lp1Kzp27KjTe0xNzYZSWfpHZmtrBpksS6e5qXp6mpGDz7ZegLGBPhaMbQtTo1f/bFPV4/VGVHV4vRFVPrFYBGtr3VprV+gTZQsKCmBmZlZqQg8AMTExkEgkGD58uHrMwMAAgYGBuHjxIp48eVLqHNu2bUNubi4mTpxY7Pbs7GwAgLW1ZtmEjc2LBwsZGhqWeg4iGwsjzBjmjqcZuVgfxY44REREVP3onNSfOXMGoaGhGmM7duxAmzZt0Lp1a7z33ntQKBSlzpOQkICmTZvCxMREY9zDwwMqlQoJCQmvPF4mk2HdunWYM2cOjIyMit3H1dUVxsbGWL16NeLi4vD48WPExcVh9erV6NChAzw9PUuNkwgAWjhYIsTPBQn3nmFP7G2hwyEiIiLSoHNSv3nzZty5c0f9OjExEV988QXs7Ozw1ltvITo6ukylMzKZDHZ2dlrjtra2AFDqSv2KFSvQtGlTDB48uMR9LC0tsXLlSmRlZWHcuHHo2rUrxo0bh8aNG2PDhg0QiUSlxklUxMejPvzaN0LspSSc+v2h0OEQERERqenc/ebOnTsa3W6io6NhYGCAsLAwmJqa4r333kNUVJS6Tr4kubm5xZbpGBgYAHhRX1+S+Ph4REVFYfv27aUm5nXq1IGbmxu8vLzg6OiIGzduYNOmTfjwww+xYsWKVx5bHF3qm2xtzXSen6q3qcNb42lWHnYevwWXZtbwaG4rdEj0/3i9EVUdXm9E1Y/OSX1GRgasrKzUr3/55Rd07NgRpqYvkt327dvjzJkzpc5jaGhYbJlOUTJflNy/TKVSYcmSJejTpw/atm37ynM8ePAAY8eOxfLly9GrVy8AQK9evWBvb4958+YhICAAnTt3LjXWf+KNsjTezxnJsmx88f15LAxpi7pWfC6D0Hi9EVUdXm9Ela9KbpS1srJCcnIygBc3ol65ckUjuS4oKEBhYWGp89ja2hZbYlP0NNriSnMA4Pjx44iPj8eoUaOQlJSk/lMUT1JSEnJzcwEAERERyM/P1/jNAgD06NEDAHDp0qVS4yR6mZGBPmYFuAMA1oTF43lugcARERER0ZtO56S+devW2L17N2JiYvDFF1+gsLAQXbt2VW+/d+9eiQn5P7m4uOCvv/6CXK7Z+/vy5cvq7cVJTk6GUqlESEgIevbsqf4DvEjie/bsifPnzwN48XRblUqFl7t2FhQUaPyXSFd2VsaYPtQdT57l4LsD18r02xsiIiKiyqJz+c2sWbMwduxY/Pvf/wYADB06FM2bNwfwojTmxIkT6NChQ6nz+Pn5YcuWLdi3b5+6/j4/Px8RERFo06aN+mmvycnJyMnJgaOjI4AXq+wODg5a802fPh2+vr4IDAyEq6srAKBJkyZQKpU4cuSIxg21hw4dAgC0atVK17dPpObS2Apj+jhhW8xN7D11GyN7thA6JCIiInpD6ZzUN2/eHNHR0bh06RLMzMzQrl079bbMzEyEhISUKan39PSEn58fli9fDplMhkaNGiEyMhLJycn48ssv1fvNnTsX58+fx82bNwEAjRo1QqNGjYqds2HDhuraeeDFF44tW7ZgwYIFuHr1Kpo3b45r164hLCwMzs7O6jIcovLq3toeD2VyHPvtAextTNDFs4HQIREREdEbSOekHnjRKrK4hNjCwgIhISFlnmfp0qVYtWoV9u/fj4yMDDg7O2PDhg3w9vYuT1harKysEB4ejtWrV+PkyZPYtWsXLC0tERgYiDlz5pTpIVlEpRnZszkepcqx7ehN1K1jDKeGlkKHRERERG8YkerlgvMyun//PmJjY/HgwQMAL1bJe/bsWeIqem3B7jdUHHmuAp9vuwh5jgIfhbSFjWXxD0SjysHrjajq8Hojqnzl6X5TrqR+1apV2Lhxo1aXG7FYjClTpmD27Nm6TlljMKmnkjxKe47Pt15AHXMDzP+XN4wMyvWLMCoHXm9EVYfXG1Hlq5KWlmFhYfj222/h4eGBmk4tSQAAIABJREFUb775BseOHcOxY8fwzTffoHXr1vj2228RERGh67RENV69OsZ4Z4gbkp8+x8aD16Es3y/BiIiIiHSm80r9sGHDIJFIsGPHDujra65EFhQUYMyYMVAoFLU2sedKPZXmxIUH2HniTwzo1BgB3RyFDueNwOuNqOrweiOqfFWyUp+YmIj+/ftrJfQAoK+vj/79+yMxMVHXaYlqjZ7eDujeugEOx91D3NVHQodDREREbwCdk3qJRILnz5+XuF0ul7OrDL3RRCIRRvd2gksjS3x/5AYSH2YIHRIRERHVcjon9e7u7tizZw+ePn2qtS01NRV79+6Fp6dnhQRHVFPp64kxbag7rMykCI24grTMXKFDIiIiolpM55r63377DePGjYOJiQkCAgLUT5O9ffs2IiIiIJfL8cMPP6Bt27aVErDQWFNPungoy8aS7RdhZ2WE+WO8YSDVEzqkWonXG1HV4fVGVPmqrKXlyZMn8dlnnyElJUVjvEGDBvjoo4/QvXt3XaesMZjUk67iE59i9b54eDvbYuoQN4hFIqFDqnV4vRFVHV5vRJWvypJ6AFAqlbh69SqSkpIAvHj4lKurK/bu3Ytt27YhOjq6PNNWe0zqqTxizt3H3lO3MahzEwzp0kzocGodXm9EVYfXG1HlK09SX+6n44jFYnh4eMDDw0Nj/NmzZ/i/9u49Lqo6/x/46wwMM9yvw/0iooJyEfGKdwWNSsRVzCxvZWymVrrrZmXt1y39uqvoVqaVmq22be2qIIZm4i0vqIQioOIFBGVAZQSV+31+f/SNXyyoDDJzmOH1fDz4g3Ob11gfeHPmc96f3Nzc9l6WyCA9NcgDBXfLsedkHlwdzDGot5PYkYiIiMiAaPygLBFpThAEzHrKDz3crbF1bxbybpeKHYmIiIgMCIt6Ih2RGkuw8HeBsDSTYv2uTNwvrxE7EhERERkIFvVEOmRlboLXpwShsroe63dloLauQexIREREZABY1BPpmKeTJWIi+yD3Vhn+8cNltPNZdSIiIqImbXpQ9quvvmrzBc+dO9fuMERdRUgvBSaP7I64Y9fhpjDHs6HdxI5EREREeqxNRf3f/vY3jS4qsA830WM9G+qFwrsV2PXTdbjYmyOkl0LsSERERKSn2lTUb9++Xds5iLocQRAw52k/3LlXhc3fX8I7M0Lg6WQpdiwiIiLSQ+1efKqr4uJT1NHul9fgw22pkAjA+7MHwsrcROxIeofjjUh3ON6ItK89i0/xQdkOlnL7HN47+b+Y9u/X8N7J/0XKbT5jQI9mYyHD61MCUVZZh0/jM1FX3yh2JCIiItIzLOo7UMrtc/jX5V24V3MfagD3au7jX5d3sbCnx+rmbIW5E/ogW/kA239kRxwiIiLSDIv6DrQnZz/qGuuabatrrMOenP0iJSJ9MtDPEROHdcPJzNv4MSVf7DhERESkR1jUd6B7Nfcfur2yrlLHaUgfTRzujQG+Cuw4ko2MnLtixyEiIiI9waK+A9nKbB66b/mp1TiSfwINjVxBlB5OIgiY+2wfeDhZ4POEiyi4WyF2JCIiItIDLOo70ESfCEgl0mbbpBIpJnpHwN3SFTuv7cGKlLXIvHuJc6bpoWQmRnhjShBkUiN8sjMdZZW1YkciIiKiTs5o+fLly8UOoU+qqmrxsHrczcIFdnJb3CxVoqahGrYyG0T3mohRHkMxyDkEnlbuuFxyDT8pk5HzIA9uFi6wkrEvObVkKjNGTw9rHEwtQE7BAwzxd4JEwkXdHsbcXIZK/vFDpBMcb0TaJwgCzMw0a3HNPvUaetI+9Q2NDThecBr7cpNQWV+FUJcBmNA9AtYs7qkVpy7cxubESxgV7IpZT/lyteaHYN9sIt3heCPSvvb0qW/TirLUcYwkRhjtMQyDnPvhh7xDOKo8ibNF6RjvNRZjPUbAxEj6+ItQlxEa4IyCuxXYd/oG3BUWCOvvLnYkIiIi6oRY1IvETGqGKT0jMcJtCHZn78P31/fjRMFpRPk8jQFOwbwjS00mj+qOW8UV+PbgNTjbmcHf207sSERERNTJ8EFZkTmaKfD7oNl4s9+rsJCa4R+XvkXs2Q24/iBP7GjUSUgEAa9M6ANXBzNs3H0Bt4rZEYeIiIiaY1HfSfSy9cFbA9/AjN7P4V71Paw9uxFbL3yD4qoSsaNRJ2AqM8YbU4JgJBHwya5MVFTXPf4kIiIi6jLY/UZDj+p+81vt6Q4gCAI8LF0xzHUIjAQjnLqVip8KklHbUAsvKw9IJZwt1ZWZyaXwcbPGwdR85N0qxeA+TpBwmhYAduMg0iWONyLta0/3Gxb1GtJmUf8rY4kxetn6YLBzfzyoKcPxglM4Vfgz5MYyuFm4QCLwA5auyt5aDlsLGQ6kKlFZXY8gH3uxI3UKLDKIdIfjjUj7WNTrgC6K+l+ZGssR7BiAAHs/3CxT4ljBKaSrLkJhZg+FKYu5rsrL2RJVNfU4mKqEtbkJurlYiR1JdCwyiHSH441I+9pT1It6y7e2thZr1qzB8OHDERQUhOeeew6nTp3S+DoxMTHw9fXFypUrW91fVFSEZcuWYfjw4QgMDER4eDhWrVr1pPF1xsvKA4tDXsPcgBmoaajFp+e3YGP6VtyuuCN2NBLJc2N6IKC7Hb5JuorLN+6JHYeIiIhEJmpR//bbb2Pbtm2YOHEili1bBolEgpiYGKSlpbX5GkePHkVqaupD9xcUFCA6OhppaWmYNWsW/vznPyMqKgoqlaoj3oLOCIKAEMcgvD9kCSb5PIOc+3lYmfJ3/PvKbpTXshtKVyORCJg3MQCOtqbYEJ+JovtVYkciIiIiEYm2omxGRgamTp2Kd955B3PmzAEA1NTUYMKECXB0dMQ333zz2GvU1tYiMjISkZGRWL9+PWbNmoVly5Y1O2bu3LkoKyvD9u3bIZfLnzj3k64o21HKasuxNzcJJwpOQ24sQ0S3MIxyH8aHabuYO/cqsWJbKqwtZFg2sz9MZV3zvz9XuCTSHY43Iu1rz4qyot2p379/P6RSKaZOndq0TSaTITo6GmfPnkVRUdFjr7F9+3ZUV1dj7ty5re7PycnBiRMnsGDBAsjlclRVVaG+vr7D3oOYLE0s8Lzv7/DuoMXwtvJCfPZerDizFueLMiHS32kkAidbM8z/XSDulFTiiz0X2/QHJxERERke0Yr6rKwseHt7w9zcvNn2oKAgqNVqZGVlPfJ8lUqFjRs3YvHixTA1NW31mOTkZACAiYkJJk+ejODgYAQHB+ONN95ASYlh9H93tXDGguC5mN93Lowlxth84Wt8lPY5bpYqxY5GOtLbyxYvjOuFjJxi7DyaI3YcIiIiEoFon9WrVCo4OTm12K5QKADgsXfq161bB29vb0RFRT30mBs3bgAAFi1ahOHDh+PVV19FdnY2Pv/8cyiVSuzYsQNGRkZP8C46D397X/jZ9kDyrRQkXj+A1anrMcg5BBN9ImAjsxY7HmnZmH5uKFCVY3/KTbg6mGN4kIvYkYiIiEiHRCvqq6urIZVKW2yXyWQAfplf/zAZGRnYvXs3vv76awiPWHynsrISABAYGIi1a9cCAJ566inY2Njggw8+wJEjRxAeHq5Rbk3mNykUlhpduyNMdhqPiD4jEJe1H/uuHsZ5VSYi/cZhot84yI1lOs9DuvPG8yEoKavF9h+vwLe7Pfp4d622p2KMN6KuiuONqPMRraiXy+Woq2u51P2vxfyvxf1/U6vVWLlyJcaPH48BAwY89jUAYMKECc22T5w4ER988AHOnTuncVHfWR6UfZynXMPR37Yfduf8gJ0X9yLp2nFM9InAIOcQLl5lwOY+64cV21KxYusZvD97ABysW5+aZmjEHm9EXQnHG5H26dWDsgqFotUpNr+2mnR0dGz1vKSkJGRkZGD69OlQKpVNXwBQXl4OpVKJ6urqptcAAHv75ncsLS0tYWJigtLS0g57P52Rg6k9XgmYgcUhr8FaZoWvs/6D1anrce3edbGjkZaYy6V4IzoI9Q1qfLIzE9W1hvFgOBERET2aaEW9n58fcnNzUVHRvMd6enp60/7WFBYWorGxEbNnz0ZYWFjTFwDExcUhLCwMKSkpAAB/f38AwJ07zRdpKikpQW1tLezs7Dr0PXVWPWy88acBCzG7z/Moqy3HR2mfY3Pmdqgqi8WORlrgYm+O1yb5o+BuOTZ/fwmN7IZERERk8ESbfhMREYGtW7dix44dTX3qa2trERcXh5CQkKaHaAsLC1FVVQUfHx8AwNixY+Hu7t7iegsWLMCYMWMQHR3dVMwPHjwYtra2iIuLw+TJkyGR/PI3zI4dOwAAoaGh2n6bnYZEkGCQcwiCFQE4dPM4Dtw8gsy7WRjtPgwR3cJgJu0a0zS6igBvezwf1hPfHryG+GPXMWWUj9iRiIiISItEK+r79u2LiIgIxMbGQqVSwdPTE/Hx8SgsLMSqVauajlu6dClSUlJw5coVAICnpyc8PT1bvaaHh0ezOfIymQxLlizBsmXLMHfuXISHhyMnJwfffvstRo8e3aWK+l+ZGJngae8whLoOwPfXf8Th/OM4fTsVz3qPx3DXwTCSGEY3IALC+7ujQFWBvaduwM3BHEP8ncWORERERFoi6vKTq1evxkcffYSEhAQ8ePAAvr6+2LRpE/r3799hrxEdHQ2pVIotW7Zg1apVsLGxwezZs7Fo0aIOew19ZCOzxszez2G0+zDsuvY9/nN1N35SJmNyj2fhb+/3yK5CpB8EQcCM8b1wu6QSW/ddhqOtGbq7Wokdi4iIiLRAUHP5UY3oS/cbTajVamTcvYT47ESoqorhZ9sTk3tOgJsFe50bgrLKWny4LRV19Y14f/YA2FnJxY7U4fRpvBHpO443Iu3Tq+431HkIgoC+Cn+8N/iPmNIzEjfKlFiV8hH+dXkXSmv5g1vfWZqZ4M3oIFTXNWB9XCZq6hrEjkREREQdzGj58uXLxQ6hT6qqatGWzzbMzWWorKzVfqAOJBEk8Lb2wlDXQahrrMPJwjM4UXAaAgR4Wrpzvr0eszI3gbvCAkkp+bh9rwoDfBUGNcVKH8cbkb7ieCPSPkEQYGZmotE5LOo1ZMhF/a9MjEzgb++H/o5BKKq6i2MFp5ByJw3WJpZwMXcyqGKwK3G2M4OJVIKDqUpIBAG+nrZiR+ow+jzeiPQNxxuR9rWnqOf0G3ooJ3NHzAt6Ca8Hx8DUWI6tF/+FtWc3IvfBTbGjUTtFDPLE0ABn7D6Ri9TLLRd/IyIiIv3Eop4ey8+uJ94e+CZe9IvG3epixJ79FF9d/BdKqu+JHY00JAgCZkf4wsfNClsSL+HGbT4zQUREZAjY/UZDhtj9RhPV9dVIunEUh/KPAQDGeozEeK/RkBsbXkcVQ/agohYfbvsZajXw/uwBsLGQiR3piRjqeCPqjDjeiLSP3W9I6+TGckT6RODPQ/6EvooA/HjjMP5yeg2SC1PQqG4UOx61kbW5Cd6YEoSK6jp8GpeJunp2xCEiItJnLOqpXezktnjJ/wUs6b8Q9nI7fHN5J/7688e4XHJN7GjURp5OloiZ0AfXC0vxjx8ugx/aERER6S92v9FQV+h+owlbuTVCXQbC2dwRF4ov4yflSeSXKeFh4QYLE3Ox49FjuDqYQyIASalKSI0l6OVhI3akdukq442oM+B4I9I+trTUARb1LQmCAFcLZ4xwHQKZkQwpt8/hiPIkKuoq4GXlARMjzf6nJN3q5WGD2yWVOJSqhKejBVzs9e+Psa403ojExvFGpH1saUmikhpJMb7bGPxP6FsY6jIQPymT8ZdTq3E4/zjqG+vFjkcPIQgCXn6mN7ycLbHp+0vILyoXOxIRERFpiEU9dTgrE0tM95uCdwYtgqelO3Zd+x4rz6xDuuoi5213UiZSI7w+JQimMiN8sjMDpbwLR0REpFdY1JPWuFm4YGHwK3gt6CUIggSbMrfhk7RNyC8rEDsatcLWUobXpwShtLIWG+IyUVfPbkZERET6gnPqNcQ59ZoRBAGOZgoMdx0MSxNLnC1Kx9H8kyiuvoduVh6QG+t3f3RDY2spg5OtKQ78nI/7ZTUI7ukAQRDEjvVYHG9EusPxRqR97ZlTb6ylLETNGEmMMMp9KAY69cP+vEM4qjyJc0UZGO85GmGeI/kwbScyqLcTClQV+D45D+4Kc4wf5Cl2JCIiInoMFvWkU2ZSU0zuOQEj3EKxO2cvEnMP4EThGUT5PI0BTsGQCJwR1hlEjfBG4d0K/PtINpztzRHkYy92JCIiInoEVlAkCoWZPWICZ2FRv3mwNLHAtkvfITZ1A7Lv54odjQBIBAGvTOgDD4UFvthzAYV3K8SORERERI/Aop5E1dO2O94a8Dpm9Z6G+zUP8Pdzn2HLhX/iblWx2NG6PJnJLx1xpMa/dMQpr6oTOxIRERE9BIt6Ep1EkGCwS3/8T+hbeMZ7HC7ezcKHp2MRn70XVfVVYsfr0uyt5Vg4ORAlZdXYGJ+J+gZ2xCEiIuqM2P1GQ+x+oz3GEiP0svXBEJcBKKstx/GCU0gu/BlyYxncLVw5314kdlZy2FnJkZSqRHlVHfr2cBA7Ugscb0S6w/FGpH3t6X7Dol5DLOq1T24sR19FAALteyO/vADHCk7hvOoCHEztoTDrfAVlV+DpZInaugYkpSphYSpFd1crsSM1w/FGpDscb0Ta156inrc+qdPytHLHon7zEBMwE3UNddiQ/iU2nP8StyruiB2tS5oyygfBPRzw7cFruJhXInYcIiIi+g0W9dSpCYKAYMdAvDdkCX7X41nklt7A/6b8Hd9diUdZbbnY8boUiURATGQfuDiY4bP4C7hTUil2JCIiIvo/LOpJL0glxgj3HIXlQ5ZihNsQnCw8g+WnViPpxlHUNdaLHa/LMJUZ440pQZBIBHy8MwOV1eyIQ0RE1BmwqCe9YmFijud6TcKyQYvhY9MNu3P24cPTsThXlAF1Wx52oCemsDHFgt8FQHW/Cp8lXERDIzviEBERiY1FPeklZ3MnzO/7Mhb2fQUyIxN8eeGf+Pu5z3CjNF/saF2Cr6ctZj7li4u5Jfj34Wyx4xAREXV57H6jIXa/6VwUZvYY5joINjJrpBVl4ojyBFSVxfCycoepsVzseAbNy9kSldX1OJiqhI2FCbo5i9cRh+ONSHc43oi0rz3db4y1lIVIZ4wkRhjuNgT9nYJx4MYRHM4/jvOqTIR7jkS452jIjWViRzRYz431wa3iCvzzwFU425nB19NW7EhERERdEqffkMEwNZYjyudp/HnwEgQ59MEPeYfwwenVOFX4MxrVnPetDUYSCeZF+UNhY4oN8RdQdJ8rABMREYmBRT0ZHHtTO7wc8CL+2H8BbOW2+OflHVj98ye4ei9H7GgGyUwuxZvRQVCr1Vi/MwNVNexGREREpGss6slgdbf2wh/7z8dLfaajvK4SH6d9gU0Z21BUqRI7msFxsjPDa5MCcKu4Epv2XERjIzsRERER6RIflNUQH5TVL4IgwNXCBcPdhsDEyARnbp/FUWUyKuur0M3KA1IjqdgRDYbCxhQWZlIkpSpRV98If287nb02xxuR7nC8EWkfH5QleggTIykiuo1FqMtAJF7/EUfyT+DMrbN42jscI91CYSQxEjuiQRgb4o4CVQV+OHMTrg7mGBboInYkIiKiLoHTb6hLsZZZ4sXe0Xh74Jtws3TFzmt7sCJlLTLvXuLiVR1kenhP9Payxbb9l5GtfCB2HCIioi5B1KK+trYWa9aswfDhwxEUFITnnnsOp06d0vg6MTEx8PX1xcqVKx95XHp6Ovz8/ODr64vS0tL2xiYD4G7pijeCYzAvaA4A4POMf2D9+c1QlhWKG8wAGBtJ8NqkANhZyvFpXAaKH1SLHYmIiMjgiVrUv/3229i2bRsmTpyIZcuWQSKRICYmBmlpaW2+xtGjR5GamvrY49RqNVasWAFTU9MniUwGRBAEBDr0wXuD/ojonhORX1aAv/78Mb7J2okHNWVix9NrFqZSvBEdhLqGRnyyKwPVteyIQ0REpE2iFfUZGRnYu3cvlixZgrfeegvTpk3Dtm3b4OLigtjY2DZdo7a2FqtWrcLcuXMfe2x8fDxu3ryJKVOmPGl0MjBGEiOM8RiO5aFLMdpjGE7fTsVfTv8N+/MOo7ahTux4esvVwRzzogKgVJVjS2IWGjm9iYiISGtEK+r3798PqVSKqVOnNm2TyWSIjo7G2bNnUVRU9NhrbN++HdXV1Y8t6svLy7Fu3TosXLgQ1tbWT5ydDJO51AzRPSfivcF/hK9tT3x/fT8+OL0GqbfTON++nQK722Pa2J44d1WF3cdzxY5DRERksEQr6rOysuDt7Q1zc/Nm24OCflnEJisr65Hnq1QqbNy4EYsXL37slJqNGzfCwsIC06dPf+LcZPiczBR4NWg23uz3e5hLzfDVpW8Re3YDrj+4IXY0vTRugDtGBLkgMTkPpy/dFjsOERGRQRKtqFepVHB0dGyxXaFQAMBj79SvW7cO3t7eiIqKeuRxeXl52L59O5YuXQpjY3bwpLbrZdsDSwe+gRl+U1FSfQ9rz27A1gvfoLiqROxoekUQBMx8yhe93K3x1b7LyL3Fh9SJiIg6mmhVbnV1NaTSlgv/yGQyAEBNTc1Dz83IyMDu3bvx9ddfQxCER77OqlWrMHDgQIwZM+bJAv8fe3uLNh+rUFh2yGuSuCY6jsX4PkORcDkJ319JQsbdi3jWNwyTej8FMykfvG6rP8eE4g8fH8OG+EysWzQK9tYd+2/H8UakOxxvRJ2PaEW9XC5HXV3LhxB/LeZ/Le7/m1qtxsqVKzF+/HgMGDDgka9x7NgxHD9+HPHx8U8e+P8UF5ejsfHx86sVCkuoVOygYkjGOo9GP5tgJOTsx+6sH3Eo+yQmdB+Poa6DIBG45ENbLJwUgJX/PIvlm05h6YshkEk7ZtEvjjci3eF4I9I+iUTQ6EYyIOL0G4VC0eoUG5VKBQCtTs0BgKSkJGRkZGD69OlQKpVNX8AvD8QqlUpUV//SF3vNmjUYO3YszM3Nm477tT99YWFhmx7GJfotW7kN5vg/jz8NWAiFmQO+vRKHVSkfIavkqtjR9IK7owV+H9kHN26X4at9WXwAmYiIqIOIdqfez88PX3/9NSoqKpo9LJuent60vzWFhYVobGzE7NmzW+yLi4tDXFwcNm/ejJEjR+LWrVu4evUqkpKSWhwbFRWFvn374j//+U8HvSPqSrpZeeIPIa8hTZWJ3dn78On5LfC398PkHs/C2dxJ7HidWr+eCkwZ7YOdR3Pg5mCOyGHeYkciIiLSe6IV9REREdi6dSt27NiBOXPmAPil73xcXBxCQkLg5PRLYVRYWIiqqir4+PgAAMaOHQt3d/cW11uwYAHGjBmD6Oho+Pv7AwBiY2NRX9980Zu9e/di3759WLNmDVxcXLT4DsnQCYKAEMcgBNr3xlHlSezPO4yVKX/HCLcheKbbOFiYmD/+Il3U04M9UaCqQPzxXLjYm2OAX+ufzBEREVHbiFbU9+3bFxEREYiNjYVKpYKnpyfi4+NRWFiIVatWNR23dOlSpKSk4MqVKwAAT09PeHp6tnpNDw8PhIeHN30/evToFsf82ipz9OjRsLKy6sB3RF2V1EiKcV6jMcRlAPbmJuGY8hRSbp/D093CMcp9KIwl7Lr03wRBwJynfVF0rxJb9l6CwsYUXs588I6IiKi9RH26b/Xq1Zg5cyYSEhKwYsUK1NfXY9OmTejfv7+YsYjaxdLEAs/7/g7vDlqMblaeiMtOxIdn1uK86gLnjrdCamyEhZMDYS6XYn1cBh6UP7zjFRERET2aoGa1oRF2v6G2ulh8BXHZibhdcQc9bLwxpUckPK1aTh3r6m7cLsOqb87CQ2GBt17oB6mx5h1xON6IdIfjjUj72tP9xmj58uXLtRPHMFVV1aItfwaZm8tQWVmr/UDUaTmaOWC462BYmVghrSgDR5UncbeqBF5WHpAby8WO12nYWMjgbGeGAz/no/hBDUJ6OTx2/Yn/xvFGpDscb0TaJwgCzMxMNDqHRb2GWNSTJiSCBF5WHhjuNhiN6kacKkzBMWUyGtSN8LLygLGkY/q06ztXB3MIAnAwVQmZ1Ag93W00Op/jjUh3ON6ItK89RT2f4CPSAVNjU/yux7MY4TYEu7P3YV9uEpILUzCxewQGOvfj4lUAIod2Q+HdCuw8mgMXe3ME93QQOxIREZHeYCVBpEMOpvZ4JXAmFoe8BisTS2zP+jfWpK7HtXvXxY4mOkEQ8NIzveHpbIkvvr8IZVG52JGIiIj0Bot6IhH0sPHGnwYsxOw+z6O0thwfpX2OzZnboaosFjuaqGRSI7wxJQhyEyN8sisDpfyIn4iIqE1Y1BOJRCJIMMg5BP8z5E+Y4D0el4qv4MMzsYi7lojKuiqx44nG1lKG1ycH4UFFLTbGZaK+oVHsSERERJ0eH5TVEB+UpY5mJDFCT9vuGOIyAOV1FThRcBonb52BiZEJPCxcu+R8e1tLGRQ2chz4WYn75TUI7vHojjgcb0S6w/FGpH3sfqMDLOpJW+TGcvRV+CPQoQ+UZYU4XnAKaUWZsJfbQmGqeZtHfeeusEBDYyMOpiphJpfCx836ocdyvBHpDscbkfa1p6jvercAiTo5D0s3vNnvVfw+cBYa1A34LOMrbEj/EoXlt8WOpnOTRnRHSC8F/n34GjKvd+3nDYiIiB6FRT1RJyQIAvoqAvDe4D9iSs9I5JXm439T/o5vL+9CaW3XWclRIgh4ZUJvuCss8HnCBdwqrhA7EhERUafEop6oEzOWGGOsxwgsD30Lo9yHIvnWz/jLqdU4kHcEdQ11YsfTCbmJMV6fEgipkQQf78xAeVXXeN9ERESaYFFPpAcspOaY2isK7w36A3radkfC9R/w4ZlYnL2TDnVbHvLQcw7Wplg4OQglpdX4bPcFdsQhIiL6LyzqifQWjn5AAAAUwElEQVSIk7kj5gW9hNeDYyA3lmPrxW+w7txG5JXeFDua1vVwt8bsCD9k3biHbw9dEzsOERFRp8LuNxpi9xvqDBxM7THMdTBs5dZIU2XiSP4JFFWq4GXlDlNjU7HjaY2nkyVq6hpwMFUJSzMpvF2sAHC8EekSxxuR9rWn+42xlrIQkZZJBAmGuQ5Gf8e+OHDjKA7lH0O66gLCPEZinNdoyI3lYkfUiuhRPii8W4F/JV2Di50ZenezEzsSERGR6AR1V5iQ24GKi8vR2Pj4fzKFwhIqVdfpUkLiK666hz3Xf0DqnfOwMrFEZPenMMRlgEEuXlVVU4+VX5/F3fuVMJNL8aC8FnZWMkwe5YNQf2ex4xEZNP5+I9I+iUSAvb2FRudw+o2GOP2GOiszqSn6OQaij10v5JXm41jBKWTcvQhHUwUcTA3rbrbUWIK6hkZk5JSgurYBAFBV04AL14thby2Hh6NmPwiJqO34+41I+7j4FBHB29oLf+w/Hy/7v4Cq+mp8cn4TPs/4CncqVWJH61AHf85vsa22vhFxP+WIkIaIiEhcnFNPZIAEQUB/p2AEOfjjSP4J/HjjMFacWYtRbkPxtHc4zKVmYkd8YsWlNRptJyIiMmQs6okMmNRIivHdxmCI6wAkXj+Ao8qTOHP7LJ72DsdIt1AYS/T3R4C9lazVAt7eSiZCGiIiInFx+g1RF2BlYokX/KbgnUGL4Gnpjl3XvsfKM+uQrrqot4tXTR7lAxPj5j/CTIwlmDzKR6RERERE4mH3Gw2x+w3pO7VajYvFlxGXvRd3KovQy8YHk3tGwsPSVexoGjt18TbifspBSWkNu98Q6Qh/vxFpX3u637Co1xCLejIUDY0NOFF4BntzD6CyrgpDXAYgsvtTsJZZiR1NYxxvRLrD8Uakfe0p6vV3Qi0RPREjiRFGuQ/FQKdg/JB3CD8pk3G2KB3jPccgzHMETIw0a6VFRERE4uGdeg3xTj0ZqqLKu0jI2YfzqguwkVkjyudpDHAK1ovFqzjeiHSH441I+zj9RgdY1JOhu3YvB7uyE5FfVgAvSw9M6RkJH5tuYsd6JI43It3heCPSPhb1OsCinrqCRnUjUm6fw56c/XhQW4p+jkGY5PNMp12ZluONSHc43oi0j3PqiahDSAQJhrgMQD/HIBy8cRRJN39CpuoixniMwFPdxsDU2FTsiERERPQbLOqJ6KFkRiZ4tvt4DHMbjD05+5F08yhO3foZE7qPx1CXQTCSGIkdkYiIiMDpNxrj9Bvqym6U5mPXtUTkPMiFi7kTJveYgD72vmLH4ngj0iGONyLt45x6HWBRT12dWq1GuuoC4rP34m51CfrY+WJyzwlwMXcSLRPHG5HucLwRaR+Leh1gUU/0i7rGevykPIn9eYdQ01CLYa6D8az3OFiaaPZDqCNwvBHpDscbkfbxQVki0hmpxBjhnqMw2Lk/9uUexInC0/j5dhoiuo3FaI/hkEr444WIiEhXeKdeQ7xTT9S6WxV3EJ+9FxeLL8NebodJPZ5BP0UgBEHQ+mtzvBHpDscbkfa15069qEtF1tbWYs2aNRg+fDiCgoLw3HPP4dSpUxpfJyYmBr6+vli5cmWz7bdu3cL69esRHR2NgQMHYvDgwZg5c2a7XoOIHs3F3Anz+76MhX1fgYmRFF9e+Cf+fu4z3CjNFzsaERGRwRO1qH/77bexbds2TJw4EcuWLYNEIkFMTAzS0tLafI2jR48iNTW11X2HDh3Cli1b4OXlhUWLFmH+/PmoqKjAnDlzsHv37o56G0T0G73te+GdgYsw3XcyiirvYnXqemy79B3uVd8XOxoREZHBEm36TUZGBqZOnYp33nkHc+bMAQDU1NRgwoQJcHR0xDfffPPYa9TW1iIyMhKRkZFYv349Zs2ahWXLljXtv3btGuzt7WFnZ9fsnKioKNTU1ODw4cMa5+b0G6K2q6qvxoEbR3A4/zgECAj3HIVwz1GQG8s69HU43oh0h+ONSPv0avrN/v37IZVKMXXq1KZtMpkM0dHROHv2LIqKih57je3bt6O6uhpz585tdX/Pnj2bFfQAYGJiglGjRqGgoADV1dVP9iaI6JFMjeWI8nka7w9egiCHPvgh7yA+OL0ap26lolHdKHY8IiIigyFaUZ+VlQVvb2+Ym5s32x4UFAS1Wo2srKxHnq9SqbBx40YsXrwYpqaaLVmvUqlgZmYGmaxj7xYSUescTO3wcsCL+GP/+bCR2+CfWf/B6p8/wdV7OWJHIyIiMgiiFfUqlQqOjo4ttisUCgB47J36devWwdvbG1FRURq97o0bN5CUlISIiAiddOUgov+vu3U3LOm/AHP6TEd5XSU+TvsCmzK2oahSJXY0IiIivSZaI+nq6mpIpdIW23+9e15TU/PQczMyMrB79258/fXXGhXmVVVVePPNN2FqaorFixdrHhrQaH6TQmHZrtcgMnTPOI5EeO8hSLx6CPFZP2JFyjpE9BiNKf5Pw8LE/PEXaAXHG5HucLwRdT6iFfVyuRx1dXUttv9azD9saoxarcbKlSsxfvx4DBgwoM2v19DQgMWLFyMnJwdffvllq58StAUflCXqOCMUwxFk1ReJ1/dj39XDOHr9FJ7xHocRbkNgJDFq83U43oh0h+ONSPv0akVZhULR6hQbleqXj+EfVnQnJSUhIyMDixcvhlKpbLavvLwcSqUSDg4OkMvlzfa99957+Omnn7B27VoMGjSog94FET0pa5klXuw9FaPch2FXdiJ2XEvAsYJk/K7Hswiw781pckRERG0g2px6Pz8/5ObmoqKiotn29PT0pv2tKSwsRGNjI2bPno2wsLCmLwCIi4tDWFgYUlJSmp3zt7/9DXFxcXj33XfxzDPPaOHdENGTcrd0xRvBMZgXNAdqqPF5xj/w6fktKCi/JXY0IiKiTk+0O/URERHYunUrduzY0dSnvra2FnFxcQgJCYGTkxOAX4r4qqoq+Pj4AADGjh0Ld3f3FtdbsGABxowZg+joaPj7+zdt37JlC7Zu3Yp58+Zh5syZ2n9jRNRugiAg0KEPetv1wvGC09iXm4RVKR8h1GUgJnR/CtYyzuMlIiJqjWhFfd++fREREYHY2FioVCp4enoiPj4ehYWFWLVqVdNxS5cuRUpKCq5cuQIA8PT0hKenZ6vX9PDwQHh4eNP3SUlJWLNmDbp164bu3bsjISGh2fHjxo2DmZmZFt4dET0JY4kxxngMxyDnEPyQdxA/KZNxtug8xnuNxViPETAxavmQPRERUVcmWlEPAKtXr8ZHH32EhIQEPHjwAL6+vti0aRP69+/fIde/fPkyACAvLw9vvfVWi/2HDh1iUU/UiZlLzRDdcyJGuIVid/Y+fH99P04UnMYkn6fR3ykYP99Jw56c/bhfcx82MhtM9InAIOcQsWMTERHpnKBWqx/fyoWasPsNkXiulGQjLjsRyvJCOMjtcL+mFPXq+qb9UokUL/hNYWFPpEX8/Uakfe3pfiPag7JERJryteuBpQPfwIt+U1Fcfa9ZQQ8AdY112JOzX6R0RERE4mFRT0R6RSJIMNR1INRo/ROzezX3dZyIiIhIfCzqiUgv2cpsNNpORERkyFjUE5FemugTAamkeRccqUSKiT4RIiUiIiISj6jdb4iI2uvXh2HZ/YaIiIhFPRHpsUHOIRjkHMJuHERE1OVx+g0RERERkZ5jUU9EREREpOdY1BMRERER6TkW9UREREREeo5FPRERERGRnmNRT0RERESk51jUExERERHpORb1RERERER6jkU9EREREZGe44qyGpJIBK0cS0RPhuONSHc43oi0qz1jTFCr1WotZCEiIiIiIh3h9BsiIiIiIj3Hop6IiIiISM+xqCciIiIi0nMs6omIiIiI9ByLeiIiIiIiPceinoiIiIhIz7GoJyIiIiLScyzqiYiIiIj0HIt6IiIiIiI9x6KeiIiIiEjPGYsdwJAUFRVh+/btSE9Px4ULF1BZWYnt27dj8ODBYkcjMigZGRmIj4/HmTNnUFhYCBsbG/Tr1w+LFi2Cl5eX2PGIDEpmZiY+//xzXLp0CcXFxbC0tISfnx8WLFiAkJAQseMRGbTNmzcjNjYWfn5+SEhIeOSxLOo7UG5uLjZv3gwvLy/4+voiLS1N7EhEBmnLli04d+4cIiIi4OvrC5VKhW+++QaTJk3Czp074ePjI3ZEIoORn5+PhoYGTJ06FQqFAmVlZfj+++8xY8YMbN68GcOGDRM7IpFBUqlU+Oyzz2BmZtam4wW1Wq3WcqYuo7y8HHV1dbC1tcXBgwexYMEC3qkn0oJz584hICAAJiYmTdvy8vIQGRmJZ599Fn/9619FTEdk+KqqqhAeHo6AgAB88cUXYschMkhvv/02CgsLoVarUVpa+tg79ZxT34EsLCxga2srdgwigxcSEtKsoAeAbt26oWfPnsjJyREpFVHXYWpqCjs7O5SWloodhcggZWRkYM+ePXjnnXfafA6LeiIyCGq1Gnfv3uUf1kRaUl5ejpKSEly/fh3r1q3D1atXERoaKnYsIoOjVqvx4YcfYtKkSejdu3ebz+OceiIyCHv27MGdO3ewePFisaMQGaR3330XP/74IwBAKpXi+eefx7x580RORWR4du/ejezsbGzYsEGj81jUE5Hey8nJwQcffID+/fsjKipK7DhEBmnBggWYNm0abt++jYSEBNTW1qKurq7FVDgiar/y8nKsXbsWv//97+Ho6KjRuZx+Q0R6TaVS4dVXX4W1tTU+/vhjSCT8sUakDb6+vhg2bBimTJmCL7/8EhcvXtRovi8RPd5nn30GqVSKl156SeNz+duPiPRWWVkZYmJiUFZWhi1btkChUIgdiahLkEqlCAsLw4EDB1BdXS12HCKDUFRUhG3btuGFF17A3bt3oVQqoVQqUVNTg7q6OiiVSjx48OCh53P6DRHppZqaGsybNw95eXn4xz/+ge7du4sdiahLqa6uhlqtRkVFBeRyudhxiPRecXEx6urqEBsbi9jY2Bb7w8LCEBMTgyVLlrR6Pot6ItI7DQ0NWLRoEc6fP4+NGzciODhY7EhEBqukpAR2dnbNtpWXl+PHH3+Ei4sL7O3tRUpGZFjc3d1bfTj2o48+QmVlJd59911069btoeezqO9gGzduBICmXtkJCQk4e/YsrKysMGPGDDGjERmMv/71rzh8+DDGjBmD+/fvN1uQw9zcHOHh4SKmIzIsixYtgkwmQ79+/aBQKHDr1i3ExcXh9u3bWLdundjxiAyGpaVlq7+/tm3bBiMjo8f+buOKsh3M19e31e1ubm44fPiwjtMQGaaZM2ciJSWl1X0ca0Qda+fOnUhISEB2djZKS0thaWmJ4OBgvPzyyxg0aJDY8YgM3syZM9u0oiyLeiIiIiIiPcfuN0REREREeo5FPRERERGRnmNRT0RERESk51jUExERERHpORb1RERERER6jkU9EREREZGeY1FPRERERKTnWNQTEVGnN3PmTIwdO1bsGEREnZax2AGIiEgcZ86cwaxZsx6638jICJcuXdJhIiIiai8W9UREXdyECRMwcuTIFtslEn6YS0SkL1jUExF1cX369EFUVJTYMYiI6AnwNgwRET2SUqmEr68v1q9fj8TERERGRiIwMBCjR4/G+vXrUV9f3+Kcy5cvY8GCBRg8eDACAwPxzDPPYPPmzWhoaGhxrEqlwooVKxAWFoaAgACEhobipZdewsmTJ1sce+fOHfzhD3/AwIED0bdvX8ydOxe5ublaed9ERPqEd+qJiLq4qqoqlJSUtNhuYmICCwuLpu8PHz6M/Px8vPjii3BwcMDhw4fx6aeforCwEKtWrWo6LjMzEzNnzoSxsXHTsUeOHEFsbCwuX76MtWvXNh2rVCoxffp0FBcXIyoqCgEBAaiqqkJ6ejqSk5MxbNiwpmMrKysxY8YM9O3bF4sXL4ZSqcT27dsxf/58JCYmwsjISEv/QkREnR+LeiKiLm79+vVYv359i+2jR4/GF1980fT95cuXsXPnTvj7+wMAZsyYgYULFyIuLg7Tpk1DcHAwAGDlypWora3Fd999Bz8/v6ZjFy1ahMTERERHRyM0NBQA8Je//AVFRUXYsmULRowY0ez1Gxsbm31/7949zJ07FzExMU3b7OzssGbNGiQnJ7c4n4ioK2FRT0TUxU2bNg0REREtttvZ2TX7fujQoU0FPQAIgoBXXnkFBw8eRFJSEoKDg1FcXIy0tDSMGzeuqaD/9djXXnsN+/fvR1JSEkJDQ3H//n0cP34cI0aMaLUg/+8HdSUSSYtuPUOGDAEA3Lhxg0U9EXVpLOqJiLo4Ly8vDB069LHH+fj4tNjWo0cPAEB+fj6AX6bT/Hb7b3Xv3h0SiaTp2Js3b0KtVqNPnz5tyuno6AiZTNZsm42NDQDg/v37bboGEZGh4oOyRESkFx41Z16tVuswCRFR58OinoiI2iQnJ6fFtuzsbACAh4cHAMDd3b3Z9t+6fv06Ghsbm4719PSEIAjIysrSVmQioi6DRT0REbVJcnIyLl682PS9Wq3Gli1bAADh4eEAAHt7e/Tr1w9HjhzB1atXmx27adMmAMC4ceMA/DJ1ZuTIkTh27BiSk5NbvB7vvhMRtR3n1BMRdXGXLl1CQkJCq/t+LdYBwM/PD7Nnz8aLL74IhUKBQ4cOITk5GVFRUejXr1/TccuWLcPMmTPx4osv4oUXXoBCocCRI0dw4sQJTJgwoanzDQC8//77uHTpEmJiYjBp0iT4+/ujpqYG6enpcHNzw5/+9CftvXEiIgPCop6IqItLTExEYmJiq/sOHDjQNJd97Nix8Pb2xhdffIHc3FzY29tj/vz5mD9/frNzAgMD8d133+GTTz7Bt99+i8rKSnh4eGDJkiV4+eWXmx3r4eGBXbt2YcOGDTh27BgSEhJgZWUFPz8/TJs2TTtvmIjIAAlqfr5JRESPoFQqERYWhoULF+L1118XOw4REbWCc+qJiIiIiPQci3oiIiIiIj3Hop6IiIiISM9xTj0RERERkZ7jnXoiIiIiIj3Hop6IiIiISM+xqCciIiIi0nMs6omIiIiI9ByLeiIiIiIiPceinoiIiIhIz/0/5XC0nbet6fcAAAAASUVORK5CYII=\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"7_8Maihw4c5b","colab_type":"text"},"source":["## bring in 2020 test labels"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4P-D-_0RvF_c"},"source":["## Prepare the test set"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0DpC0NLCvIhQ","colab":{}},"source":["input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in X_test:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 64,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(y_test)\n","\n","# Set the batch size.  \n","batch_size = 32  \n","\n","# Create the DataLoader.\n","prediction_data = TensorDataset(input_ids, attention_masks, labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"42eXX3Dlvhq5"},"source":["## Test Set Predictions"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vsz6SLS4vZKm","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1591222722430,"user_tz":420,"elapsed":1708,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}},"outputId":"656cdeeb-a887-4330-e9b3-5694924685b2"},"source":["print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n","\n","# Put model in evaluation mode\n","model.eval()\n","\n","# Tracking variables \n","predictions , true_labels = [], []\n","\n","# Predict \n","for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  \n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels = batch\n","  \n","  # Telling the model not to compute or store gradients, saving memory and \n","  # speeding up prediction\n","  with torch.no_grad():\n","      # Forward pass, calculate logit predictions\n","      outputs = model(b_input_ids, token_type_ids=None, \n","                      attention_mask=b_input_mask)\n","\n","  logits = outputs[0]\n","\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  true_labels.append(label_ids)\n","\n","print('    DONE.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Predicting labels for 300 test sentences...\n","    DONE.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AZxySb0UyuGP","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ynAp7wGXvq3f","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1591222722432,"user_tz":420,"elapsed":269,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}},"outputId":"a233516b-9170-4084-8d3d-931cde94c399"},"source":["print('Positive samples: %d of %d (%.2f%%)' % (y.sum(), len(y), (y.sum() / len(y) * 100.0)))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Positive samples: 730 of 1565 (46.65%)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"l6UQ5oVuw_YM","colab":{}},"source":["flat_predictions = np.concatenate(predictions, axis=0)\n","\n","# For each sample, pick the label (0 or 1) with the higher score.\n","flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","\n","# Combine the correct labels for each batch into a single list.\n","flat_true_labels = np.concatenate(true_labels, axis=0)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iBiBj4DRxV1a","colab":{}},"source":["from sklearn.metrics import classification_report"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ypWWn52jyAq7","colab":{}},"source":["f = classification_report(flat_true_labels, flat_predictions, target_names = [\"class 0\", \"class 1\"],\n","                          output_dict = True)\n","class_f = pd.DataFrame(f).transpose()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AWRIEHzwNKZQ","colab_type":"code","colab":{}},"source":["class_f.to_csv(output_name + \".csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZAKj3_u_i_4U","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1591222727069,"user_tz":420,"elapsed":406,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}},"outputId":"d5aff6ed-20be-4170-adf1-fde6c0547683"},"source":["class_f"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>class 0</th>\n","      <td>0.89</td>\n","      <td>0.84</td>\n","      <td>0.86</td>\n","      <td>207.00</td>\n","    </tr>\n","    <tr>\n","      <th>class 1</th>\n","      <td>0.68</td>\n","      <td>0.76</td>\n","      <td>0.72</td>\n","      <td>93.00</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>0.81</td>\n","      <td>0.81</td>\n","      <td>0.81</td>\n","      <td>0.81</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>0.78</td>\n","      <td>0.80</td>\n","      <td>0.79</td>\n","      <td>300.00</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>0.82</td>\n","      <td>0.81</td>\n","      <td>0.82</td>\n","      <td>300.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              precision  recall  f1-score  support\n","class 0            0.89    0.84      0.86   207.00\n","class 1            0.68    0.76      0.72    93.00\n","accuracy           0.81    0.81      0.81     0.81\n","macro avg          0.78    0.80      0.79   300.00\n","weighted avg       0.82    0.81      0.82   300.00"]},"metadata":{"tags":[]},"execution_count":88}]},{"cell_type":"markdown","metadata":{"id":"NCuMhvTo5Ufg","colab_type":"text"},"source":["## Lets run our model on the real test data"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"T6rSNZwUu-oZ","colab":{}},"source":["checkthat2020 = []\n","with open(\"CT20-AR-Test-T1-Tweets.json\") as f:\n","    for line in f:\n","        checkthat2020.append(json.loads(line))\n","checkthat2020_test = pd.DataFrame.from_records(checkthat2020)[['full_text']]\n","checkthat2020_test = checkthat2020_test['full_text'].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"god4OLDjpaEj","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1cP8Ap_t63iQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1591222733664,"user_tz":420,"elapsed":854,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}},"outputId":"4540e68a-07a0-4630-8747-376c61ce4d37"},"source":["len(checkthat2020_test)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6000"]},"metadata":{"tags":[]},"execution_count":90}]},{"cell_type":"code","metadata":{"id":"yGlXy4G85M2_","colab_type":"code","colab":{}},"source":["input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in checkthat2020_test:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 64,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","#labels = torch.tensor(y_test)\n","\n","# Set the batch size.  \n","batch_size = 32  \n","\n","# Create the DataLoader.\n","prediction_data = TensorDataset(input_ids, attention_masks)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yTjze0f_5TKB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1591222759691,"user_tz":420,"elapsed":25863,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}},"outputId":"6ff365eb-33de-4e9f-aa52-4770bc2ce356"},"source":["print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n","\n","# Put model in evaluation mode\n","model.eval()\n","\n","# Tracking variables \n","predictions = []\n","\n","# Predict \n","for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  \n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask = batch\n","  \n","  # Telling the model not to compute or store gradients, saving memory and \n","  # speeding up prediction\n","  with torch.no_grad():\n","      # Forward pass, calculate logit predictions\n","      outputs = model(b_input_ids, token_type_ids=None, \n","                      attention_mask=b_input_mask)\n","\n","  logits = outputs[0]\n","\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  #label_ids = b_labels.to('cpu').numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  #true_labels.append(label_ids)\n","\n","print('    DONE.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Predicting labels for 6,000 test sentences...\n","    DONE.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5IB20PyX59Ny","colab_type":"code","colab":{}},"source":["flat_predictions = np.concatenate(predictions, axis=0)\n","\n","# For each sample, pick the label (0 or 1) with the higher score.\n","label_predictions = np.argmax(flat_predictions, axis=1).flatten()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tbS7Qwyb5BRH","colab_type":"code","colab":{}},"source":["raw_predictions = np.concatenate(predictions, axis=0)\n","\n","#For each sample, pick the label (0 or 1) with the higher score.\n","soft_predictions = softmax(raw_predictions, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ql8qbuBpqFYb","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V4hcMXePnE_h","colab_type":"text"},"source":["## Merge predictions with final dataframe and fix column names"]},{"cell_type":"code","metadata":{"id":"tvNhzGTDkZcr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":232},"executionInfo":{"status":"error","timestamp":1591236623975,"user_tz":420,"elapsed":717,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}},"outputId":"1c2cea39-f70b-4100-fffc-527d3c23ae81"},"source":["data = []\n","with open(\"CT20-AR-Test-T1-Tweets.json\") as f:\n","    for line in f:\n","        data.append(json.loads(line))\n","tweets = pd.DataFrame.from_records(data)\n","\n","labdf = pd.DataFrame(data=soft_predictions, columns=[\"label_0\", \"label_1\"])\n","labdf['score'] = labdf['label_1'] - labdf['label_0']\n","\n","tweets = tweets[['id', 'full_text', 'topicID']]\n","#preds = pd.read_table(\"../results/final/Accenture_bumpy_predictions.txt\", header= None)\n","finalpreds = labdf\n","tweets['score'] = finalpreds['score']\n","tweets[\"rank\"] = tweets.groupby(\"topicID\")[\"score\"].rank(\"dense\", ascending=False).astype(int)\n","tweets = tweets.sort_values(['topicID', 'rank'])\n","tweets['id'] = tweets['id'].astype(str)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-15cd473f7995>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CT20-AR-Test-T1-Tweets.json\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'CT20-AR-Test-T1-Tweets.json'"]}]},{"cell_type":"code","metadata":{"id":"1ANqe0kp9GN8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":289},"executionInfo":{"status":"ok","timestamp":1591222760701,"user_tz":420,"elapsed":22650,"user":{"displayName":"Evan Williams","photoUrl":"","userId":"00292228211353941613"}},"outputId":"4123d73d-8d6c-44ce-86cd-7276432c0ae6"},"source":["tweets.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>full_text</th>\n","      <th>topicID</th>\n","      <th>score</th>\n","      <th>rank</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>410</th>\n","      <td>1222607381668024320</td>\n","      <td>#بلجيكا.. وقفة أمام السفارة الأمريكية تنديدا ب...</td>\n","      <td>CT20-AR-01</td>\n","      <td>0.85</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>175</th>\n","      <td>1222274380039888896</td>\n","      <td>#عاجل  لجنة المتابعة العليا للقوى الوطنية والإ...</td>\n","      <td>CT20-AR-01</td>\n","      <td>0.82</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>482</th>\n","      <td>1222809405625982978</td>\n","      <td>🔴 تحرك مهم من #تركيا 🇹🇷🇵🇸 \\n\\nوكالة الأنباء ال...</td>\n","      <td>CT20-AR-01</td>\n","      <td>0.79</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>102</th>\n","      <td>1222234308531904517</td>\n","      <td>مكبرات مساجد الضفة الغربية تصدح بآيات القتال ف...</td>\n","      <td>CT20-AR-01</td>\n","      <td>0.77</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>475</th>\n","      <td>1222644840413839360</td>\n","      <td>إصابة 7 فلسطينيين في مواجهات مع الجيش الإسرائي...</td>\n","      <td>CT20-AR-01</td>\n","      <td>0.76</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                      id  ... rank\n","410  1222607381668024320  ...    1\n","175  1222274380039888896  ...    2\n","482  1222809405625982978  ...    3\n","102  1222234308531904517  ...    4\n","475  1222644840413839360  ...    5\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":96}]},{"cell_type":"code","metadata":{"id":"aYMHeJ5V_AYZ","colab_type":"code","colab":{}},"source":["final = tweets.copy()\n","final.rename(columns = {\"id\":\"tweetID\"}, inplace = True)\n","final['runID'] = run_name\n","final = final[['topicID', 'rank', 'tweetID', 'score', 'runID']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aLhTMtleD16i","colab_type":"code","colab":{}},"source":["final.to_csv(run_name + '.txt', sep='\\t', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6qAh6afDAE6k","colab_type":"code","colab":{}},"source":["extest = pd.read_table(run_name + \".txt\", sep = \"\\t\")\n","extest['tweetID'] = extest['tweetID'].astype(str)\n","extest['dummy'] = 1\n","extest = extest[['dummy', 'tweetID']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oTgKJJAT6fcK","colab_type":"code","colab":{}},"source":["assert len(extest.merge(tweets, left_on='tweetID', right_on='id')) == 6000, \"AHHHHHH\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5cRmudYtO-k7","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}